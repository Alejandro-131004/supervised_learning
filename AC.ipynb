{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "# Supervised Learning\n",
    "\n",
    "Work assembled by Alejandro Gon√ßalves, Pedro Fernandes, Francisca Mihalache."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "\n",
    "2. [Chosen Algorithm](#chosen-algorithm)\n",
    "\n",
    "3. [Metrics](#metrics)\n",
    "            \n",
    "4. [Distances](#distances)\n",
    "   - 4.1. [Euclidian Distance](#euclidian-distance)\n",
    "   - 4.2. [L2 Distance](#l2-distance)\n",
    "   - 4.3. [Euclidian Distance (features)](#euclidian-distance-features)\n",
    "   - 4.4. [Cosine Similarity](#cosine-similarity)\n",
    "   - 4.5. [Manhattan Distance](#manhattan-distance)\n",
    "   - 4.6. [Jaccard Distance](#jaccard-distance)\n",
    "\n",
    "5. [Base](#base)\n",
    "\n",
    "6. [Improved Algorithm](#improved-algorithm)\n",
    "\n",
    "7. [Comparisons](#comparisons) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this assignment we'll dive into a selected Machine Learning (ML) algorithm, understanding its theory and testing its performance. We'll explore benchmarking methodologies and differentiate between ML research and practical application, ensuring a balanced understanding of theory and practice in ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "To begin with, we need to import some modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import autograd.numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "from numpy.linalg import norm\n",
    "from sklearn.decomposition import PCA\n",
    "import openml as oml\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from math import sqrt\n",
    "from numpy import array\n",
    "from matplotlib.colors import ListedColormap\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, GridSearchCV, RandomizedSearchCV,cross_validate,LeaveOneOut\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, mean_absolute_error,mean_squared_error, r2_score, f1_score,ConfusionMatrixDisplay,roc_curve,roc_auc_score, auc\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <th>Cell_Size_Uniformity</th>\n",
       "      <th>Cell_Shape_Uniformity</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epi_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Clump_Thickness  Cell_Size_Uniformity  Cell_Shape_Uniformity  \\\n",
       "0   1                5                     1                      1   \n",
       "1   2                5                     4                      4   \n",
       "2   3                3                     1                      1   \n",
       "3   4                6                     8                      8   \n",
       "4   5                4                     1                      1   \n",
       "\n",
       "   Marginal_Adhesion  Single_Epi_Cell_Size Bare_Nuclei  Bland_Chromatin  \\\n",
       "0                  1                     2           1                3   \n",
       "1                  5                     7          10                3   \n",
       "2                  1                     2           2                3   \n",
       "3                  1                     3           4                3   \n",
       "4                  3                     2           1                3   \n",
       "\n",
       "   Normal_Nucleoli  Mitoses   Class  \n",
       "0                1        1  benign  \n",
       "1                2        1  benign  \n",
       "2                1        1  benign  \n",
       "3                7        1  benign  \n",
       "4                1        1  benign  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('csvs\\\\breast.csv')\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                       0\n",
      "Clump_Thickness          0\n",
      "Cell_Size_Uniformity     0\n",
      "Cell_Shape_Uniformity    0\n",
      "Marginal_Adhesion        0\n",
      "Single_Epi_Cell_Size     0\n",
      "Bare_Nuclei              0\n",
      "Bland_Chromatin          0\n",
      "Normal_Nucleoli          0\n",
      "Mitoses                  0\n",
      "Class                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# If exists any missing values\n",
    "print(df1.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleja\\AppData\\Local\\Temp\\ipykernel_1588\\727482383.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df1['Class'] = df1['Class'].replace({'benign': 0, 'malignant': 1})\n",
      "C:\\Users\\aleja\\AppData\\Local\\Temp\\ipykernel_1588\\727482383.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df1['Bare_Nuclei'].replace('?', np.nan, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <th>Cell_Size_Uniformity</th>\n",
       "      <th>Cell_Shape_Uniformity</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epi_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Clump_Thickness  Cell_Size_Uniformity  Cell_Shape_Uniformity  \\\n",
       "0   1                5                     1                      1   \n",
       "1   2                5                     4                      4   \n",
       "2   3                3                     1                      1   \n",
       "3   4                6                     8                      8   \n",
       "4   5                4                     1                      1   \n",
       "\n",
       "   Marginal_Adhesion  Single_Epi_Cell_Size  Bare_Nuclei  Bland_Chromatin  \\\n",
       "0                  1                     2          1.0                3   \n",
       "1                  5                     7         10.0                3   \n",
       "2                  1                     2          2.0                3   \n",
       "3                  1                     3          4.0                3   \n",
       "4                  3                     2          1.0                3   \n",
       "\n",
       "   Normal_Nucleoli  Mitoses  Class  \n",
       "0                1        1      0  \n",
       "1                2        1      0  \n",
       "2                1        1      0  \n",
       "3                7        1      0  \n",
       "4                1        1      0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing benign with 0 and malignant with 1 to be easier to understand and removing the lines that \"?\" is present. \n",
    "df1['Class'] = df1['Class'].replace({'benign': 0, 'malignant': 1})\n",
    "df1['Bare_Nuclei'].replace('?', np.nan, inplace=True)\n",
    "df1['Bare_Nuclei'] = pd.to_numeric(df1['Bare_Nuclei'], errors='coerce')\n",
    "df1.dropna(subset=['Bare_Nuclei'], inplace=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Clump_Thickness</th>\n",
       "      <th>Cell_Size_Uniformity</th>\n",
       "      <th>Cell_Shape_Uniformity</th>\n",
       "      <th>Marginal_Adhesion</th>\n",
       "      <th>Single_Epi_Cell_Size</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>683.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>352.355783</td>\n",
       "      <td>4.442167</td>\n",
       "      <td>3.150805</td>\n",
       "      <td>3.215227</td>\n",
       "      <td>2.830161</td>\n",
       "      <td>3.234261</td>\n",
       "      <td>3.544656</td>\n",
       "      <td>3.445095</td>\n",
       "      <td>2.869693</td>\n",
       "      <td>1.603221</td>\n",
       "      <td>0.349927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>202.563927</td>\n",
       "      <td>2.820761</td>\n",
       "      <td>3.065145</td>\n",
       "      <td>2.988581</td>\n",
       "      <td>2.864562</td>\n",
       "      <td>2.223085</td>\n",
       "      <td>3.643857</td>\n",
       "      <td>2.449697</td>\n",
       "      <td>3.052666</td>\n",
       "      <td>1.732674</td>\n",
       "      <td>0.477296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>177.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>356.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>527.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>699.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  Clump_Thickness  Cell_Size_Uniformity  \\\n",
       "count  683.000000       683.000000            683.000000   \n",
       "mean   352.355783         4.442167              3.150805   \n",
       "std    202.563927         2.820761              3.065145   \n",
       "min      1.000000         1.000000              1.000000   \n",
       "25%    177.500000         2.000000              1.000000   \n",
       "50%    356.000000         4.000000              1.000000   \n",
       "75%    527.500000         6.000000              5.000000   \n",
       "max    699.000000        10.000000             10.000000   \n",
       "\n",
       "       Cell_Shape_Uniformity  Marginal_Adhesion  Single_Epi_Cell_Size  \\\n",
       "count             683.000000         683.000000            683.000000   \n",
       "mean                3.215227           2.830161              3.234261   \n",
       "std                 2.988581           2.864562              2.223085   \n",
       "min                 1.000000           1.000000              1.000000   \n",
       "25%                 1.000000           1.000000              2.000000   \n",
       "50%                 1.000000           1.000000              2.000000   \n",
       "75%                 5.000000           4.000000              4.000000   \n",
       "max                10.000000          10.000000             10.000000   \n",
       "\n",
       "       Bare_Nuclei  Bland_Chromatin  Normal_Nucleoli     Mitoses       Class  \n",
       "count   683.000000       683.000000       683.000000  683.000000  683.000000  \n",
       "mean      3.544656         3.445095         2.869693    1.603221    0.349927  \n",
       "std       3.643857         2.449697         3.052666    1.732674    0.477296  \n",
       "min       1.000000         1.000000         1.000000    1.000000    0.000000  \n",
       "25%       1.000000         2.000000         1.000000    1.000000    0.000000  \n",
       "50%       1.000000         3.000000         1.000000    1.000000    0.000000  \n",
       "75%       6.000000         5.000000         4.000000    1.000000    1.000000  \n",
       "max      10.000000        10.000000        10.000000   10.000000    1.000000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols1 = ['Clump_Thickness','Cell_Size_Uniformity']\n",
    "X1 = df1[cols1]\n",
    "y1 = df1['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Clump_Thickness', ylabel='Cell_Size_Uniformity'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGxCAYAAACXwjeMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABry0lEQVR4nO3deXgU9eE/8Pfs7JG9N5s7EO77RkEEFEVQpIrifdVqrcfPoqio34L1rHer1tKv1eq3xaOereCB1YqACHIIQgAFOQTkzJ2975n5/UGJxGRDdpPs7JD363n2eWQ+ye573OzOe2c+MysoiqKAiIiISKN0agcgIiIiaguWGSIiItI0lhkiIiLSNJYZIiIi0jSWGSIiItI0lhkiIiLSNJYZIiIi0jSWGSIiItI0vdoBOposyzh48CDsdjsEQVA7DhEREbWCoijw+/0oLS2FTtfyvpfjvswcPHgQZWVlascgIiKiNOzbtw9du3Zt8WeO+zJjt9sBHP6f4XA4VE5DREREreHz+VBWVtawHW/JcV9mjhxacjgcLDNEREQa05opIpwATERERJrGMkNERESaxjJDREREmnbcz5lpLUmSEI/H1Y7RIQwGA0RRVDsGERFRh+j0ZUZRFFRUVMDj8agdpUO5XC4UFxfzWjtERHTc6fRl5kiRKSwshMViOe429oqiIBQKoaqqCgBQUlKiciIiIqL21anLjCRJDUUmLy9P7Tgdxmw2AwCqqqpQWFjIQ05ERHRc6dQTgI/MkbFYLCon6XhH1vF4nRdERESdV6cuM0ccb4eWmtMZ1pGIiDonVcvMF198gWnTpqG0tBSCIOC9995rNK4oCu6//36UlJTAbDZj8uTJ2LFjhzphKavFPNWI1R5ArO4QEuGQ2nHSlgh4EKs7hFjdIUiRoNpx0hb31SJWexDx2oOI+2vVjpO2RKAesbqDh9fFW612nE5PioT++3wcQLy+Qu04aUskYojVHmx4z9KyeO2hw89HrbrroeqcmWAwiOHDh+O6667DhRde2GT897//PebOnYtXXnkFPXv2xH333YcpU6Zgy5YtyMnJUSFx6wmCgAULFmD69OlqRzmuJUI+xGv2o27Ja4ge2A7BkAP7sNPhHDMNhtxiteO1mhyP/nc9/oHwns2AKMI2aDxyT7kEBrd2Jm3HYjHAcwh1y95EaMfXAABLv1Fwn3YljAXa+sLXWO0B1K/4J4JbVwGSBHPPoXCfcTVEVxH0OVa143U68fpK+DZ8Cv/6TyFHQzAW9YR74lXQ53WF0VWgdrxWi9dXIrBlBXxrP4IU9MLgLkXuaZfDVNoXBleh2vFaLeapRPj7cnhWzofkq4HoyIdr3IWw9BoBQ25RxvOoumdm6tSpeOSRR3DBBRc0GVMUBc8++yzuvfdenH/++Rg2bBheffVVHDx4sMkeHDVUVFTg1ltvRa9evWAymVBWVoZp06Zh8eLFakfrVOK1B3DoHw8gemA7AECJR+D7+hNU/uv3iNdp55NbvL4CB1+9F+E9mwAogJRAYPMyHHrjIU2tB3zVOPja/QhtXwsoMqDICG37Cgdfuxex2gNqp2u1WN0hHHrjdwh+sxyQEgAUhHdvwsFXfgvJV6N2vE4nXl+B6oXPwbvqPcjRw3teY5W7UfHWI4hX7VE3XArinmrULXsT9Z+/ASnoPbys7iCqFjyD8PcbIMVjKidsnYS/Hv71i1D7yYsNrwfJV4PaT16Er3wREoH6jGfK2jkzu3fvRkVFBSZPntywzOl0YsyYMVi1apWKyYA9e/bgxBNPxJIlS/CHP/wBmzdvxieffIKJEydixowZqmbrTOLeatQtfu3wRvMnYlU/IFa7X4VUqUuEA/Cs+BeURNM3soS3GqE9m1RIlTopEoK//DPIkUCTMTkcgH/TUkixiArJUhfeVd5saVESMXhWLVDlzbozSwTqEdn7bbNjdYtfRaxeG4dq5FgIwW+XNztWt+xNzRRlORqE96sPmx3zrvkQsgqHyLO2zFRUHP40WlTUeHdVUVFRw1hzotEofD5fo1t7+/Wvfw1BEPDVV1/hoosuQr9+/TB48GDMmjULq1evbvZ3fvOb36Bfv36wWCzo1asX7rvvvkZnFm3cuBETJ06E3W6Hw+HAiSeeiHXr1gEAfvjhB0ybNg25ubmwWq0YPHgw/v3vf7f7emmNkogjemBb0vHQzvUZTJM+JRJA+Idvko6Hd34NKRbNYKL0SGEfwrs3Jh0P79oIOejJXKA0JUI+hHZ+nXQ8smdzw94ByozI3q1Jx+J1B6FoZI9GvHpf0jE57FelBKRDCnr/u8eyucEEpJA3s4FwHF5n5vHHH8dDDz3UYfdfV1eHTz75BI8++iis1qbHzV0uV7O/Z7fb8fLLL6O0tBSbN2/GDTfcALvdjv/5n/8BAFx11VUYOXIknn/+eYiiiPLychgMBgDAjBkzEIvF8MUXX8BqtWLLli2w2Wwdto6aIQgQjDlQknzaF62ODAdKk6CDzmSFHGq+eOtybBA0cG0gnaiHroW5JLocKwTRkMFE6dHpjcdYDxsgZO3nwOOSaLEnH9SJEHTZ//oA0OLfFQAI+ux/fQCAoDe2abwjZO0rsrj48OTNysrKRssrKysbxpozZ84ceL3ehtu+fcmbcDp27twJRVEwYMCAlH7v3nvvxbhx49CjRw9MmzYNd911F955552G8b1792Ly5MkYMGAA+vbti0suuQTDhw9vGBs/fjyGDh2KXr164dxzz8WECRPadb20SLS6YB9+RtJx64CxGUyTPtGRD8eJU5KO20eeCZ2Y/Z879I58OEZNTTruHDUVekf2X5xSZ8yBY+RZSccdJ5wFo4YmZR8PcsoGAkkKi7X/GAgmbVwrTO8qhC5JVlPX/hCM2lgPndkGvav5Sb56VxFEU+Y/bGdtmenZsyeKi4sbTaj1+XxYs2YNxo5NvpEymUxwOByNbu1JUZS0fu/tt9/G+PHjUVxcDJvNhnvvvRd79+5tGJ81axauv/56TJ48GU888QS+//77hrGZM2fikUcewfjx4/HAAw9g0yZtzKHoaKLJDOfoc2Es7tlkLG/K9dCZtbFnRqfTwTrgZOT0HNZkzDn2Ak2d4WAq7g3roFOaLLcOOQ3Goh6ZD5QmvbMAzjHTmiw39xwOS99RKiTq3ASTBYXnz2yyR8zgLkHu6VfCYHerlCw1OnseCi+6u8meC9GWi4Kf/T8Yc7XxWje6S1A4/Y4mxUxnsqDwglkw5GW+7AtKulvndhAIBLBz504AwMiRI/HMM89g4sSJcLvd6NatG5588kk88cQTjU7N3rRpU0qnZvt8PjidTni93ibFJhKJYPfu3ejZs2er76+urg75+fl49NFHMWfOnKQ/d/Sp2atWrcKpp56Khx56CFOmTIHT6cRbb72Fp59+utEXXG7fvh0fffQRPv74YyxbtgxvvfVWw5le+/btw0cffYRPP/0UCxcuxNNPP41bb721VZnTXVetiNVXIlF3EKGd6yFaHLD0Pwk6swMGe67a0VIS91Yj4alCcNsaCMYc2AacDNGWC71NY+tRXwkp6EFw2xoAgHXAydBZnDCqcLpmW8TqK6FEAgh8txpKIgZrv5Ogd+Rp6pT/40ncVwslGkJwxzpI/jqYewyBoaCb5vaSJSIhyIE6hHdtRKzuEMxd+8NU2kdTl2AAgHg8DMVXh8jerYhW7oGpuAdyug6E4CxsmCLRVi1tv5tQVLR06VIFQJPbNddcoyiKosiyrNx3331KUVGRYjKZlEmTJinbtm1L6TG8Xq8CQPF6vU3GwuGwsmXLFiUcDqd0n2effbbSpUsXJRAINBmrr69XFEVRACgLFixQFEVRnnrqKaVXr16Nfu5Xv/qV4nQ6kz7G5ZdfrkybNq3ZsdmzZytDhw5NKXO660pERKSGlrbfP6XqYabTTz8diqI0ub388ssADu/d+N3vfoeKigpEIhF89tln6Nevn5qRAQDPPfccJEnCSSedhHfffRc7duzA1q1bMXfu3GYPgfXt2xd79+7FW2+9he+//x5z587FggULGsbD4TBuueUWfP755/jhhx/w5ZdfYu3atRg4cCAA4Pbbb8d//vMf7N69G+vXr8fSpUsbxoiIiDq77J9VmIV69eqF9evX49FHH8Wdd96JQ4cOoaCgACeeeCKef/75Jj9/3nnn4Y477sAtt9yCaDSKc845B/fddx8efPBBAIAoiqitrcUvfvELVFZWIj8/HxdeeGHDWVmSJGHGjBnYv38/HA4Hzj77bPzxj3/M5CoTERFlLVXnzGRCe8+Z0arOtK5ERKR9qcyZydqzmYiIiIhag2WGiIiINI1lhoiIiDSNZYaIiIg0jWWGiIiINI1lhoiIiDSNZYaIiIg0jWWGiIiINI1lhoiIiDSNZUbDnnvuOfTo0QM5OTkYM2YMvvrqK7UjERERZRzLjEa9/fbbmDVrFh544AGsX78ew4cPx5QpU1BVVaV2NCIiooximWkH/lAM+6v82PZDHfZX+eEPxTr8MZ955hnccMMN+OUvf4lBgwbhhRdegMViwd///vcOf2wiIqJswm/NbqNqTxh/fmcDNmyrblg2sn8Bbr10JApc5g55zFgshq+//hpz5sxpWKbT6TB58mSsWrWqQx6TiIgoW3HPTBv4Q7EmRQYANmyrxp/f2dBhe2hqamogSRKKiooaLS8qKkJFRUWHPCYREVG2YplpA28g2qTIHLFhWzW8gWiGExEREXU+LDNtEAzH2zServz8fIiiiMrKykbLKysrUVxc3CGPSURElK1YZtrAaja0aTxdRqMRJ554IhYvXtywTJZlLF68GGPHju2QxyQiIspWLDNt4LSZMLJ/QbNjI/sXwGkzddhjz5o1Cy+99BJeeeUVbN26FTfffDOCwSB++ctfdthjEhERZSOezdQGdosRt146stmzmWZeOhJ2i7HDHvuyyy5DdXU17r//flRUVGDEiBH45JNPmkwKJiIiOt4JiqIoaofoSD6fD06nE16vFw6Ho9FYJBLB7t270bNnT+Tk5KT9GP5QDN5AFMFwHFazAU6bqUOLTDraa12JiIgyoaXt909xz0w7sFuMWVdeiIiIOgvOmSEiIiJNY5khIiIiTWOZISIiIk1jmSEiaoEsy0hIstox2kxRZChSQu0YbaYoCmSuR1aRYupf7Z4TgImImuENRLG/KoCPV+5GNC5j8kll6NPVhTxnx3yBbEeRwn7E6yvh//o/kCJ+WAeOh7nbIOgdeWpHS4kUCSHhrYJvwyJIvhpY+o6CudcIGJzNX+srW8nxKBLeavg3LkG89gByug2GdcAY6J0FEATt7F+QY1EkvFXwb16GePVeGAq7wz50AvSOQuiMHXeNtWRYZoiIfsITiGLeh99iybp9DctWf3MIfbs68dvrxmim0EjhALyrP4Bn5fyGZaHta6HPLUbJVQ9qpgjIsTCCW5aj5uMXG5aFdqyDaHWh9BePwOAuUTFd68lSHOFd5ah89ylAOby3L7RjHepX/BOlVz8MU1EPdQO2kiwnED2wDYfefhQ4sndp59fwrfkQxZfdA1P3IdDpMlvMtFMDiYgyZF+Fv1GROWLHfi+Wlx+ALGvj8lwJX02jItOwvL4C3tXvQ050zPfHtTcp4EHNxy81XR70oGbRPEiRkAqpUif561H13rMNReYIJRpC9Yd/RiLoVSdYiiRPDao++NOPRea/FCmOqg/mQvJWZTwTywwR0VESCRn/Xrk76fi/v9wDb0D9OQKtEdiyIumYf+MSyCFfBtOkL7x3C4DmC2R453rIEX9mA6UpXncISiLW7Fiscg/ksDbWQwr7IAU8zY8F6iGp8HfFMkNEdBRZURCJSUnHo3EJskYunK7EIsnHEnFo5QLwSryl8qgAsjYmaCcrMg3jcvK/u2yiSC3nVGM9WGY06osvvsC0adNQWloKQRDw3nvvqR2J6LhgNIg4Y1TXpOPjh5XAYdXGFb+tA8YmHTP3OQG6HEsG06Qvp9vgpGPGop7QmawZTJM+Y35XIMkkX9Huhmi2ZThRekSrE4Kh+Um+giEHosWZ4UQsM5oVDAYxfPhwPPfcc2pHITruDOqRh+4l9ibLHVYjzpvQGwa9qEKq1BnyuiCn25AmywWDCXkTfw7RpI0yI9pzYR1yatMBnYj8s2+AaG35e3uyhWh1wjV2ejMjAvLPvhGizZ3pSGkRbW7knn5ls2PuiVdCdGR+PXg2UzuQwgFIQS/kaBC6HCtEi7PDG/bUqVMxderUDn0Mos4qz2XGg9ePxeK1e/HJ6j2IJ2SMH1aK6af1QZFbGwUAAPQ2Fwqn34bgd6vg/eojyNEQLL1HwnXKxTDkFqsdr9X0FgfyJl0LS8/h8KxcACnkhalsINwTLochr1TteK2mM1ngHDMNptI+qF/+DhLeGhiLe8F9+hUwFpRBEAS1I7aKaMqBbeA4GNyl8Cx/B/G6QzDklcJ1yiUwFfWAaMj8lxmzzLRRwleD6oV/QXj3xoZl5l4jUHDOzdA78lVMRkRtke8y4+Iz+uLMk7pDgQK7xQijQRt7ZI6mt7vhGPUzWAeOBxQJuhwbdEkOEWQzvc0F+7CJMPcaeXg9jBboTNo4Rf5oosUBa/8xyOk6AIqUgGDMgZijjcNkR9Pb3dDb3TAW9QDiUcBghMGu3rWLWGbaQAoHmhQZAAjvKkf1R8+jcPodmjkGSkRNiaIObmfmP2W2N0EQoLe51I7RLo6X9RCtmZ9X0hEM9uw4NMY5M20gBb1NiswR4V3lkDRyzQAiIiItY5lpAzkaPMa4Ni7kREREpGUsM21wrNMBdRo5U4CIiEjLOGemDUSrE+ZeIxDeVd5kzNxrRIceEw0EAti5c2fDv3fv3o3y8nK43W5069atwx6XiIgo23DPTBuIZhsKzrkZ5l4jGi0/cjZTR07+XbduHUaOHImRI0cCAGbNmoWRI0fi/vvv77DHJCIiykbcM9NGekc+Cqff8d/rzISgM1kgWjv+OjOnn366Zi5FTkRE1JFYZtqBaLbxFGwiIiKV8DATERERaRrLDBEREWkaywwRERFpGssMERERaRrLDNApzgrqDOtIRESdU6cuMwaDAQAQCh3/XztwZB2PrDMREdHxolOfmi2KIlwuF6qqqgAAFosFgiConKp9KYqCUCiEqqoquFwuiKKodiQiIqJ21anLDAAUFxcDQEOhOV65XK6GdSUiIjqedPoyIwgCSkpKUFhYiHg8rnacDmEwGLhHhoiIjludvswcIYoiN/hEREQa1KknABMREZH2scwQERGRprHMEBERkaaxzBAREZGmscwQERGRprHMEBERkaaxzBAREZGmscwQERGRprHMEBERkaaxzBAREZGmZfXXGUiShAcffBD/+Mc/UFFRgdLSUlx77bW49957j7tvtyZKBOohR0JI+GogiCJEWy50Vhf0OVa1o6UkHvJDCfuQ8NVCEASIdjeQY4fR6lA7WkoS0SikQC3kQD0UKQG9Ix+K2QGT1a52tJQkEjHI3hpIQQ+UeBR6Zz4EowUGR57a0VIWqzsEOeSDHAlCdORDl2PV5HrEPVWQQj7IIR9ERx50OTZNrkesvhJKJAAp6IFoy4VgssKYW6RKlqwuM08++SSef/55vPLKKxg8eDDWrVuHX/7yl3A6nZg5c6ba8YjaTdxTCf/mL+BZ8S9ATgAAdDlWFEy7BUqX/jBYnSonbJ24twrhXRtR++nfoSRiAADBYELeWb+C0HM4DM58lRO2TjQUQHzft6j58H8hR0OHF4p65J56KTDkdJic2tjwJCIhxCt3oXL+05BDvsMLBR0co6bCedK5MLgK1Q3YSpIkIVG1B5X/+gMSvur/LhVgHXwK3KdfqZn1AIBYzX5UvvsHxGv2Nywz9xqB/Kk3aWs96g6i+v25iB7c0bDMVNoXBeffBqO7JON5svow08qVK3H++efjnHPOQY8ePXDxxRfjrLPOwldffaV2NKJ2Fa3YA88XbzUUGQCQI0FUvvsUlKBHvWApkny1qPn3Cw1FBgCUeBQ1H/0Fkr9WxWQp8tei6t2nfiwyACAlUP/5G0hU7VYvV4rkQB0q3nr0xyIDAIoM39qPEPp+vXrBUiR5KnHozYePKjIAoCD47XL41v8HUiyqWrZUxOsrUfHOE42KDACEd5Wj7vPXIYX9KiVLTby+EtUfPteoyABA9OAO1Cz8C+KeqoxnyuoyM27cOCxevBjbt28HAGzcuBErVqzA1KlTk/5ONBqFz+drdCPKZrH6SnhXzW9+UJbg37gUkiRlNlQaEgEPPGs+SDruXfMBEgFvBhOlR0ok4C//DFDkZsc9X85H1FOT4VTpCe3c0KhYHs276j3E6g5mOFF6YlU/QE6yofet/1QzRTkRqEOi/lCzY8EtKyEFs//1AQByLIzo/u+aHYvs29L4Q0CGZPVhptmzZ8Pn82HAgAEQRRGSJOHRRx/FVVddlfR3Hn/8cTz00EMZTEnURrKEeH1l0uF43UEo8QggZvfcGTkWQaKl9fBUQo6HAWT3ITM5FkG8hY18wlMJSPEMJkpfrGZf0rGEtxqCksEwbRCvTf58KNEQFI08HwlfCyVYkSHHwpkL0wZyJNim8Y6Q1Xtm3nnnHbz++ut44403sH79erzyyit46qmn8MorryT9nTlz5sDr9Tbc9u1L/mImygaC3gBjflnScWNxT01MAtaZLDAUtLAeBd2hM2lhPXJgLOqZdNxQUAYYcjKYKH2mkt5Jxwx5XQCNnEhhLOqedExncUAQDRlMkz6DqzjpmCAaoDNZMpgmfTqzrU3jHSGry8zdd9+N2bNn4/LLL8fQoUNx9dVX44477sDjjz+e9HdMJhMcDkejG1E2MzgL4Dr1kmbHBIMJtsGnZjhRevRWB1xjzgOEZt5WBB2cJ50LvSX7zwQSRT1sQ0+DoDc2O557yiUwOXIznCo95h5DoMtpfsOSe+qlMKgwUTMdhrwu0DsKmh1znXweRGfzY9lGtLlgLO7V7JhtxCSINneGE6VHZ7LA0ndUs2OWvqOgU+HDV1aXmVAoBJ2ucURRFCHLzR/LJtIqg7sU+efOaPSJRu8qQvHl90Ln0MYZQACgs+Wi6OK7IdpcDctEuxtFl/wGOo28UQOA6ChE0eX3Qu/88ewSndmOgmm3QpdbqmKy1OicRSi58n4Y8rs2LBOMZrgnXQNTl34qJkuN0V2C4st/C1Npn4Zlgt4I59gLYB04HqJeI3tmnAUovGAWcnoM/XGhToR9xGS4Tp4O0WRWL1wKDM4C5J15HSz9x/z44UXQwTLgZOSd+UsYVHjPEhRFydqjptdeey0+++wz/PWvf8XgwYOxYcMG3Hjjjbjuuuvw5JNPtuo+fD4fnE4nvF4v99JQVkvEIpD9dZAjAUAnQjRZNPPJ+WjxeByKr/rweggCxBwbYM+HwaCNDc7RonUVUCIBKIoMXY4doiMfeg2uR7y+AnLk8NwSndkG0ebWzIbzaHFPFeRIEEoiBl2ODTqrE3oVDmm0VcJfBzkcgBwLa3s9vDWQYyHI0TB0JjN0Jiv07Xi9nFS231ldZvx+P+677z4sWLAAVVVVKC0txRVXXIH7778fRmPzu4B/imWGiIhIe46bMtMeWGaIiIi0J5Xtd1bPmSEiIiI6FpYZIiIi0jSWGSIiItI0lhkiIiLSNJYZIiIi0jSWGSIiItI0lhkiIiLSNJYZIiIi0jSWGSIiItI0lhkiIiLSNJYZIiIi0jSWGSIiItI0lhkiIiLSNJYZIiIi0jSWGSIiItI0lhkiIiLSNJYZIiIi0jSWGSIiItK0tMrMaaedhldffRXhcLi98xARERGlJK0yM3LkSNx1110oLi7GDTfcgNWrV7d3LiIiIqJWSavMPPvsszh48CDmzZuHqqoqTJgwAYMGDcJTTz2FysrK9s5IRERElFTac2b0ej0uvPBCvP/++9i/fz+uvPJK3HfffSgrK8P06dOxZMmS9sxJRERE1Kw2TwD+6quv8MADD+Dpp59GYWEh5syZg/z8fJx77rm466672iMjERERUVKCoihKqr9UVVWF1157DfPmzcOOHTswbdo0XH/99ZgyZQoEQQAArFixAmeffTYCgUC7h06Fz+eD0+mE1+uFw+FQNQsRERG1Tirbb306D9C1a1f07t0b1113Ha699loUFBQ0+Zlhw4Zh9OjR6dw9ERERUaulVWYWL16MU089tcWfcTgcWLp0aVqhiIiIiForrTkzDzzwADweT5PlPp8PZ5xxRlszUQZJQS/inmokfLVQJEntOGmTQn7EvdVI+GogJ+Jqx0mbFAki7q1G3FcDOR5VO07aYr46xGoPHr7569SOQ8cJKRJCrO4gYrUHEK+vUDtO2hRFRsJXe/i9N+BRO06bxOsOHX4+6g6pmiOtPTPLli1DLBZrsjwSiWD58uVtDkUdT46GED30PWoXzUOs6gfocqxwjD4HjpFnQm93qx2v1eR4FLGqvahdNA/RA9sgGHJgHzkZrjHnQe/IUzteqylSArHaA6j77BWEd28CRBG2IROQe8olMLgK1Y7XavF4HHL9QdQvexOhHV8DACz9RiH3tCthKihTOR1pWby+Er4Nn8K//lPI0RCMRT3hnngV9HldYXQ1neqQrRIBDwLffAHv6vcgBb0wuEvhPuNq5HQbBNFsUzteq8U8VQh/vwGelfMh+WogOvLhGnchLL1PgEGF5yOlCcCbNm0CAIwYMQJLliyB2/3jRk+SJHzyySf461//ij179rR70HRxAnDzgju/RuXbjzVZbu41EoXn3QrR6lQhVeoiB3fg4Mv3AIrcaLmxqCeKL7tHM8UsVrMfB/52N5RE4w8JemcBSq9+BHpnvkrJUhOrOYCDr9wDOdJ44r/ObEPpNY/BmNdFpWSkZfH6ClQv/Asie79tMlZ0yWxY+2ljfqYUDqD2s5cR2NR0CkbBuTNgG3oaBJ2oQrLUJEJ+eFe/D++qBU3GnOMugHPM+dBb7G1+nA6bADxixAgIggBBEJo9nGQ2m/HnP/85tbSUcYlAPWr/87dmx8K7NiDhr9VEmZHCftR++nKTIgMAscrdiNXs10SZkWMR1K/4Z5MiAwAJbzXCP3wD+7DTMx8sRVIkDH/5Z02KDADI4QD8G5fCdcrFEI05KqQjLUsE6pstMgBQt/hVGAq6wphbkuFUqZNC3maLDADULn4V5h7DNPHBRQ554f3qw2bHvGs+hH3o6UA7lJlUpFRmdu/eDUVR0KtXL3z11VeNzmIyGo0oLCyEKGZ/q+zs5GgICU/yKzVH9m+DqbhXBhOlR4lFED3wXdLx0I51sPQclsFE6ZGjwcOHlpIIfrcK1kHjodMbMpgqdYmwF+HdG5OOh3dvhH3kZIjG4gymouNBZO/WpGPxuoNQ4k0/CGSjeM2BpGNy2A8pEtBEmZGCXkBKJBlMQAp5AXTNaKaUykz37t0BALLc9JMwaYeg0wOCrtk9GgAgWjRyOE7QQTDmQIlFmh0Wra7M5kmXIEJnskIO+ZodFs0OCLrs/4J7naiHLseafDzHCojGDCai44XY0qd8naiJQzMAoMuxtDguZPkHliMEfcuv42ONd4RWl5kPPvgAU6dOhcFgwAcffNDiz5533nltDkYdR7Q4YO0/BsHvVjUzqIeptE/mQ6VBtDrhOGEKvKvfb3bc2n9MhhOlR7Q64RxzLmo/eanZcfuJUzTxZm1w5MMxaioie7c0O+4YNRVGR/Yf9qPsk1M2ENCJgNz0jEtr/zEQTC2XhGyhdxVBZ7JAjoaajJm6DoBo1sYHSZ3ZBr2rqNk9/HpXEcSczE9kbnWZmT59OioqKlBYWIjp06cn/TlBECBp+BTfzkBnMsM96ReIVu5G4ujTGwUdii68G6ItV71wKRBEPZyjz0F4zzeIVXzfaCz/nJs1MV8GOPyasfYfg9D2dQjv2tBozHXqpTDkauewjLG4N6yDTkFwy4pGy61DToOxqIc6oUjzBJMFhefPRNV7f2q0R9ngLkHu6VfCoJHXut7uRtGlc1Dx5sON5siJtlwUTpvR8h6oLGJ0l6Bw+h2oePN3jYqZzmRB4QWzYHBnfv5SWl9noCU8mym5hK8WsaofEN6zGXpnASy9T4Bod0Nn0NahgESgHvHaAwjt+Bqi1QVLv1HQ29zQmcxqR0tJIuhFor4Cwe1fQWfIgXXAGIj2PIgtHLrJRrH6SshBD4LfrQEEwDrgZOgsThhzi9SORhoW99VCiYYQ3LEOkr8O5h5DYCjoBqMKG862UKQEEr5ahPdsQrzmAExlA5FT2ht6R/bPlTmaJMUheaoQ2bsV0co9MBX3QE7XgRBzi9tt7mwq22+WGSIiIso6Hf7dTACwdu1aLF26FFVVVU0mBD/zzDPp3i0RERFRStIqM4899hjuvfde9O/fH0VFRQ3flA2g0X8TERERdbS0ysyf/vQn/P3vf8e1117bznGIiIiIUpPWxSt0Oh3Gjx/f3lmIiIiIUpZWmbnjjjvw3HPPtXcWIiIiopSldZjprrvuwjnnnIPevXtj0KBBMBgaX7Vw/vz57RKOiIiI6FjSKjMzZ87E0qVLMXHiROTl5XHSLxEREakmrTLzyiuv4N1338U555zT3nmIiIiIUpLWnBm3243evXu3dxYiIiKilKVVZh588EE88MADCIWaflkWERERUSaldZhp7ty5+P7771FUVIQePXo0mQC8fv36dglHREREdCxplZmWvjWbiIiIKJNSLjOJRAKCIOC6665D165dOyITERERUaulPGdGr9fjD3/4AxKJREfkISIiIkpJWhOAzzjjDCxbtqy9sxARERGlLK05M1OnTsXs2bOxefNmnHjiibBarY3GzzvvvHYJR0RERHQsgqIoSqq/pNMl36EjCAIkSWpTqPbk8/ngdDrh9XrhcDjUjkNEREStkMr2O609M7IspxWMiIiIqL2lNWeGiIiIKFukXWaWLVuGadOmoU+fPujTpw/OO+88LF++vD2zERERER1TWmXmH//4ByZPngyLxYKZM2di5syZMJvNmDRpEt544432zkhERESUVFoTgAcOHIgbb7wRd9xxR6PlzzzzDF566SVs3bq13QK2FScAExERaU8q2++09szs2rUL06ZNa7L8vPPOw+7du9O5SyIiIqK0pFVmysrKsHjx4ibLP/vsM5SVlbU5FBEREVFrpXVq9p133omZM2eivLwc48aNAwB8+eWXePnll/GnP/2pXQMSERERtSStMnPzzTejuLgYTz/9NN555x0Ah+fRvP322zj//PPbNSARERFRS1o9AXju3Lm48cYbkZOTg71796KsrAyCIHR0vjbjBGAiIiLt6ZAJwLNmzYLP5wMA9OzZE9XV1W1LeRyQpQTSOBmMOogcj0GWs+erNNKlyAkox8FVtuVYFHIipnaMNpOlxHGxHpIUhxyNqB2jzSRJghQNqR2jzRRFgSwl1I7RLhLhoNoRWn+YqbS0FO+++y5+9rOfQVEU7N+/H5FI8y+Mbt26tVvAAwcO4De/+Q0+/vhjhEIh9OnTB/PmzcOoUaPa7TFSocgSEt4aBL9bjci+LTDkd4V92ETonQXQGUyqZOrs4nUVCO/9BqHta6HLscEx8kzoXYXQ291qR0tJwl+H6MEd8G/6HIIxB84TzoLBXQrR6lQ7WkridRWI1exDYPPnAADbsIkw5neFIbdY1VypintrEK87AH/5EihSDLZBp8BU2gcGV5Ha0VIS91Qh4a+Ff8MiyNEQLH1Hw9xtEAzuErWjpSTurYEU9MBf/hmkQD3MPYbB3HskjHmlakdLiRyPIuGthn/jEsRrDyCn22BYB4yB3lkAQdDORfmloB9SyAP/5mWIV++FobAb7ENOg2hxQbTaM56n1YeZXnzxRdx6661IJJI3SUVR2vWLJuvr6zFy5EhMnDgRN998MwoKCrBjxw707t0bvXv3btV9tPdhpmjFbhx87V4osaOKnKBD0cX/A0vvkRDEtKYhUZpidYdQ8ebDSHgqGy13jp0O5+hzNFNoEr5aVLzzBGKVuxottw0/A3kTf66ZQhOvr0D1R88j8sM3jZabew5D3tSbYNRIoYl7q1G35B8IblnRaLmxuBeKLrpLM4Um7qmGb91H8K75sNFyfW4xii+/F0aNFJqYvxahratQt2heo+Wi1YWSqx6EsUAbZ9HKUhzhnetR+e5TgPLj3lfBZEHp1Q/DVNRDvXApiMcjSOzfjkNvPwoctXdJEA0ovuwe6LsOhMFgaPPjdMhhphtvvBE1NTXYuHEjFEXBokWLsH79+ka3DRs2YP369W1egSOefPJJlJWVYd68eTjppJPQs2dPnHXWWa0uMu0tEfCg6v0/NS4yAKDIqHrvWSQCdark6qykaAieL99tUmQAwLvqPUgBT+ZDpUGRJfg3L2tSZAAgsHEJYrUHVUiVnsjeLU2KDACEd29CdP92FRKlJ16zv0mRAYBYxS4Evl0BWdbG4QE55G1SZAAgUV8B7+r3kAgHVEiVhkgIdYtebrJYCnpQ+9krSPhqMp8pDZK/HlXvPduoyACAEg2h+sM/IxH0qhMsRYqvDlUf/KlRkQEARYqj6oO5UPyZn4aS0j4tu92OIUOGYN68eRg/fjyGDx/e7K29fPDBBxg1ahQuueQSFBYWYuTIkXjppZda/J1oNAqfz9fo1l7ksB/xmn3NjinxCBKeqnZ7LDo2OehF8NumG5wjAlu/zGCa9EkhH/wbPk067lv/H03MoYl7q+Hb8FnScf+GRYh7azOYKD1SPAp/eQvrsXEJJF/2rwcABFp6fXyzHEqo/d4fO1J4z2YAzR9ECO8qh/zTD5hZKl53CEqS+Vexyj2Qw/4MJ0qPHPYn/bAoBeohhzJfktM6QHfNNdfAZOr4+SG7du3C888/j759++I///kPbr75ZsycOROvvPJK0t95/PHH4XQ6G27teRE/5RiTS5W49icJaokCQGlhAp0Si2YuTFsoStI3OOBwUVaU7C8ziiy1vB6JKKCFPRqy3OKEXyUR08zEfzme/DWgJOJJ6kH2aXkCtnLM9+Zs0dLrAzj2NiZbHHNbqMLrvNVlxu12o6bm8K683NxcuN3upLf2IssyTjjhBDz22GMYOXIkbrzxRtxwww144YUXkv7OnDlz4PV6G2779jW/JyUdotkO0epqflDQwaCxiWhapzOaYe45LOm4dcCYDKZJn85sg6V/8qy2oadDp4G5WKIjD9Z+JyUdtww4GYI9L4OJ0iOazLANHJ903NJnFESLK3OB2qCl14C51wjNnLRg6T4k6ZixqCcEQ04G06TPmN8VSDLJV7S7IZptGU6UHtHqhJDkb0cw5Kgyx6/V75B//OMfYbcfnqH87LPPdlSeRkpKSjBo0KBGywYOHIh333036e+YTKYO22sk2nORd/aNqHr3903GXOMvgmjRxiTN44Xe5oL7jJ/j4Ctbm3ziyek2BHqXNiab6vRGuE4+H8EtKyFHGu+eNRb2QE6XviolS40oGmAdcgp85Z9B8jc+DKN3FMA6YCz0+uwvZQCQUzYAhoIyxKsbfxjSme1wjjkXokkbG099bjFyygYisq/xl/8KBhPcp18JvSP7yyUACGY7rAPHIrh1VeMBnYi8M38JY642JmSLVidcY6fDs3L+T0YE5J99I0SbNk5YEMx25J52Beo+e7nJmHvilRDNWXw2kxquvPJK7Nu3D8uXL29Ydscdd2DNmjVYuXJlq+6jvc9mkqNhxKr3ou7zNxCr3AO9swC5p16KnLIBEC28KF+myfEo4vUV8Kz4F8J7Nh0+NfuEs2AdMA4GV4Ha8VpNURQkPJXwrH4fwe9WQ9Ab4Rh5FuzDTtfMBueIWN0h+NZ9jODWLwEIsA4aD8eJU2B0a2vPZby+Av6NS+HftBSKFIel30lwjTkPencJdDrtnEIbr69E8LtV8K3/FHI0BHPPYcgdfxF0riLojdooZcDh9QjtLofvq48ghbwwdekP94TLoHPkw6CRs/2Aw3PkIvu2on75O0h4a2As7gX36VfAWFAGndGsdrxWi3uqEKvZB8/yfyJedwiGvFK4TrkYxryuMLRTuUxl+512mZFlGTt37kRVVRXkn0xOnDBhQjp32cTatWsxbtw4PPTQQ7j00kvx1Vdf4YYbbsCLL76Iq666qlX30VFXAJYiQSixCAS9gSUmCyTCASjhAKDTQXTka2pjczQ5EfvvJEAdRKsDgk5UO1JapEgIUtADABBtbs3syfgpWYo3TPbVWRwQTRaVE6UnkUhA9lUDigKdyQK9zaV2pLTF6g4BigzBYIbBoY09Gc2Rgl4oUgKCMQdijlXtOGmLe6qgSHEIor7dL1nQ4WVm9erVuPLKK/HDDz80mQjXnteZAYCFCxdizpw52LFjB3r27IlZs2bhhhtuaPXv8+sMiIiItKfDy8yIESPQr18/PPTQQygpKWnyHU1OZ/bs8mOZISIi0p5Utt9pzcbbsWMH/vWvf6FPnz5pBSQiIiJqL2lNLBgzZgx27tzZ3lmIiIiIUpbWnplbb70Vd955JyoqKjB06NAm38EwbFjya38QERERtae05sw0d6aIIAjt/kWT7YFzZoiIiLSnw+fM7N69O61gRERERO0trTLTvXv39s5BRERElJaUyszcuXObXe50OtGvXz+MHTu2XUIRERERtVZKZeaPf/xjs8s9Hg+8Xi/GjRuHDz74oF2/bJKIiIioJSmdmr179+5mb/X19di5cydkWca9997bUVmJiIiImmi3L7Dp1asXnnjiCXz66aftdZdEREREx9Su38bXrVs3VFRUtOddEhEREbWoXcvM5s2beaYTERERZVRKE4B9Pl+zy71eL77++mvceeeduOaaa9olGBEREVFrpFRmXC5Xk2/IPkIQBFx//fWYPXt2uwQjIiIiao2UyszSpUubXe5wONC3b1/YbLZ2CUVERETUWimVmdNOOy2lO//1r3+N3/3ud8jPz0/p94iIiIhaq10nAP/UP/7xj6TzbIiIiIjaQ4eWmTS+kJuIiIgoJR1aZoiIiIg6GssMERERaRrLDBEREWkaywwRERFpWoeWmZ///OdwOBwd+RBERETUyaVdZpYvX46f//znGDt2LA4cOAAAeO2117BixYqGn3n++ed5jRkiIiLqUGmVmXfffRdTpkyB2WzGhg0bEI1GARz+jqbHHnusXQMSERERtSStMvPII4/ghRdewEsvvQSDwdCwfPz48Vi/fn27hSMiIiI6lpS+zuCIbdu2YcKECU2WO51OeDyetmbKelLYDynohRSoh85sh2h1QW9zqR0rZYmAB1LYB8lXC12OFaLFAUNusdqxUiZHQ5BCPiR8NRAMOdDbXBDtbgiCtua3S+EApJAXCW8NBFEP0e6G3u6GzmBSO1pK4qEAlLAXCV8tBEE4/FzkOGCw2tWOlhI5HkXCXwfJXwdFSkDvzIdocUI0a+s76OLxKBRfLaSgB0o8Cr0zH4LRDINDe1MA4vUVkEJeyJEQREceRLMdeluu2rFSFquvgBz2Qw75INrzIJisMLoK1I6Vslh9JZRIAFLQA9GWe3g9cotUyZJWmSkuLsbOnTvRo0ePRstXrFiBXr16tUeurJXw16J64fMI79rQsMxQUIbii2fD4NZOEYh7q1G3+FUEt65sWKZ3FqDo4t/AVNxTxWSpkYJe1K9cAN/ajwBFBgCIVheKLvkNTCW9IehElRO2TtxfC3/5EnhW/AuQEwAAXY4VBdNuRU63wRBzLConbJ24rxrh78tR++nfoSRiAADBYELeWb8Ceo2AwZGncsLWkSJBRH74BtUf/i/kaOjwQlGP3FMvg33Y6dDb3eoGbKVEOIhE1W5Uzn8acui/Xy0j6OAYNRXOk86FwVWobsBWkmUZ8crdqPzXH5DwVf93qQDr4FPgnngVDE7tFIFY9T5Uzn8K8Zr9DcvMvUYg/+wbYVCpCKQjVncQ1e/PRfTgjoZlptK+KDj/NhjdJRnPk9ZH1xtuuAG33XYb1qxZA0EQcPDgQbz++uu46667cPPNN7d3xqwhR8Oo/eyVRkUGAOLV+1DxzmNIBOpVSpYaKR6B76uPGhUZAEh4q1Hx1sOI1R1SKVlqFEVBcNsa+L76sKHIAIAU9ODQ6w8i4atRMV1qogd3wvPFWw1FBgDkSBCV7/4BkobWQ/LWoObfLzQUGQBQ4lHUfPQXTa1HwleDynef+rHIAICUQP3nryNasUu9YCmSg/WoeOvRH4sMACgyfGs/Quh77UwJkDyVOPTmw0cVGQBQEPx2OXxffwI5Hkv6u9kkVncIFf98slGRAYDwrnLULXsDiaBXpWSpiddXovrD5xoVGQCIHtyBmoV/QdxTlfFMaZWZ2bNn48orr8SkSZMQCAQwYcIEXH/99bjppptw6623tnfGrCGFPAhuXdXsWLz2ACR/XYYTpUfy1cG3YVHzY0Ev4jX7MpwoPVKgHvUr/tnsmBKPIrx7c4YTpSfuq4F35fzmB2UJ/o1LIMty8+NZJBH0wrPmg6Tj3jUfIBHM/i+elaUE/Bs+a1SQj+b5cj7i/toMp0pPaOeGRsXyaN5V7yFWdzDDidITrfoBctjf7Jhv/adIaOT5kIIeJOqb/7AY3LKycenMYnIsjOj+75odi+zb0vhDQIakdZhJEAT89re/xd13342dO3ciEAhg0KBBsNm0dSw5VXIskvQNDgASgXpoYXaDkohBiUeSjsdrNbJnRpZaLJCxqh8ymKYNEgnE6yuTDsfrDh7eIBlzMhgqdXI0jERL6+GphBwLA9bsvvaUEo8i3sJGPuGphJKIZzBR+mItfDBJeKshaOS7gOO1B5KOKdFQ0sKWbRLeFvZOKvLhbYwGyJFgm8Y7Qlp7Zl599VVs3boVRqMRgwYNwkknnQSbzYZIJIJXX321vTNmDZ3RAuiS9z+9RibUCQYTdDnJi6exsFsG06RPEPXQtzBhOadLvwymSZ9gMMGYX5Z03FjcE2KWFxng8BwfQ0EL61HQHTpT9s/9EYw5MBYlnzdmKCiDzpD9zwcAmEp6Jx0z5HUBBCGDadJnLOyedExncUDQGzOYJn0tzYkRRAN0JnMG06RPd4xJ8Mca7whplZlrr70WJ510Et59991Gy71eL375y1+2S7BsJNpcsI88s9kxU2k/iBqZVa935sM5ZlrzY64iGNylGU6UHr0tF+6JVzU7pjPbYSobkOFE6dHbc+E69dJmxwSDCbbBTc8czEZ6ix2uMecBzZ1FJujgPOlc6C3Zf0aTTifCPuz0pBvI3FMu0czZi+YeQ5J+cMk99VIYVJiomQ5jflfoHc1P8nWdfD70GpkALFqcMBY3f5KMbcQk6Kza2IboTBZY+o5qdszSdxR0OdYMJ2rDFYAfeughXH311XjwwQfbMU520xlMyD3lIthHngUcdZaMuecIFF44C3qrU8V0racTDbANPR3Ok8+HIP54nSBTaV8UX3aPpmbUm3sMRd5Z10E4as+FoaAMJT//nabOcDAWlKHg3FsafaLRu4pQfPm90GvkjBMA0NndKLr4bohHbexFuxtFl/wGOrs2zmQCDp/ZV3z5vdA7f/x/rzPbUTDtVhjyu6qYLDWCoxAlV97fKLNgNMM96RqYuvRVMVlqDLnFKL7iXphK+zQsE/RGOMdeAOugU6AT05oxkXGG3CIUXnAHcnoM/XGhToR9xGS4xpwPvTnzJSAdBmcB8s68Dpb+Y3788CLoYBlwMvLO/KUqp/0LiqKkfNRUp9OhoqICu3btwgUXXIDx48fjtddeg8/nQ2lpKSRJ6oisafH5fHA6nfB6ve32PVFyLAIp6IEcCUEw5kC0OiC2cNgmW0nREKRAPeRwAILBBNFs08yhsqMpUgKJQD3ksP/wrlqLHXqrS+1YKZMTcUi+GkhhPwSdCJ3ZBoNLO8XyiEQiAdlbBTkSAAQBYo4NgqMAer02NjhHi9dXQor4AVmGaLZDdBRAp8n1qIAcCUGR4tCZbRCtuZo53f9oCW8NpEgASjx6+BpfNhdEDRy6/Km4txpKNAQ5FoEuxwqd2QF9ls8la07CWwM5FoIcDUNnMkNnskLfjpdfSGX7nVaZEUURhw4dQmFhIfbu3YvzzjsPgiDghRdewLhx4477MkNEREQdK5Xtd1qHmY7uP926dcPKlSvRo0cPnHlm8/NJiIiIiDpKWmXmgQceaHQatsViwYIFC3DHHXc0+zUHRERERB0lrcNMWsLDTERERNqTyva71TPZPvjgA0ydOhUGgwEffJD8Kp+CIGDatOZP+yUiIiJqb63eM3PkDKbCwkLodMmPTgmCwAnARERE1CYdsmfm6O+G0cL3xBAREVHnkPZF84iIiIiyQUplZtWqVVi4cGGjZa+++ip69uyJwsJC3HjjjYhGo+0akIiIiKglKZWZ3/3ud/j2228b/r1582b86le/wuTJkzF79mx8+OGHePzxx9s9JBEREVEyKZWZ8vJyTJo0qeHfb731FsaMGYOXXnoJs2bNwty5c/HOO++0e0giIiKiZFIqM/X19Sgq+vG7YpYtW4apU6c2/Hv06NHYt29f+6UjIiIiOoaUykxRURF2794NAIjFYli/fj1OPvnkhnG/3w+DwZDs14mIiIjaXUpl5mc/+xlmz56N5cuXY86cObBYLDj11FMbxjdt2oTevXu3e0giIiKiZFL6LvuHH34YF154IU477TTYbDa88sorMBqNDeN///vfcdZZZ7V7SCIiIqJk0vpuJq/XC5vNBlEUGy2vq6uDzWZrKDj79+9HaWlpi1cM7mi8AjAREZH2pLL9TqtlOJ3OJkUGANxud6M9NYMGDcKePXvSeQgiIiKiVunQXSbH+RdyExERURbg1xkQERGRprHMEBERkaaxzBAREZGmdWiZEQShI++eiIiIiBOAiYiISNtSumheqrZs2YLS0tKOfAgiIiLq5FpdZi688MJW3+n8+fMBAGVlZaknIiIiIkpBq8uM0+nsyBxEREREaWl1mZk3b15H5iAiIiJKC0/NJiIiIk1r9Z6ZkSNHtvpU6/Xr16cdqCVPPPEE5syZg9tuuw3PPvtshzxGayUC9VASCQiiDqItF4LAXqgmT70X0YQCQRDgtJpgMueoHSkttZ4wInEJAGC3GOCwmlROlB6/14tQDBAAWIyAjYepVRUPBaGEvQAUCKIBBleh2pHSEo+EoQTrASiAToQxt1jtSGlRFBmSvx6KLEPQG6C3udSOlLZ47SEokCFAB0NeiWo5Wl1mpk+f3oExjm3t2rX461//imHDhqmaQwoHEPnhW9QtfQ3xukMQrS64xl0A66BTNP0HqVXhYBA/VAbxt4Vb8d0PHuQYRZw1ugumn9YbBXna+Zb0cDSOA9VBvLxwCzbtrIao0+HUEaW47Mz+6FJgUzteq8ViMVTVhvDqx1uxZms1AODkQYX4xdQB6FLsUjdcJxWvr4Bn9fsIbF4GJR6FqWt/uM/4BfTuEhis2imZ8fpK+DZ8Cv/6TyFHQzAW9YR74lUQ88pgcuWrHa/VEgEPAt98Ae/q9yAFvTC4S+E+42rkdBsE0ayh17qnEuHvy+FZOR+SrwaiIx+ucRfC0msEDLlFGc8jKBq4GEwgEMAJJ5yAv/zlL3jkkUcwYsSIVu+ZSeUrxI9FkST4Ny1Bzb9faDJmHzEZ7km/gJhjbdNjUGq27a7G//xlFWS58Z9xzxI77r/2ROTna+PNevdBL+760xeIJeRGywtzzXj4pnEo1UihOVTlxay5XyIQjjdabrcY8Myt41FcqI3n43gRrzuEin89iXj1vsYDgg6lv3gYOV0HqBMsRbG6CtR89BdE9n7bZKzoktmw9hutQqrUSeEAaj97GYFNS5uMFZw7A7ahp0HQiSokS03CXw/v2o/gXbWgyZhz3AVwjj4Heltumx8nle132sdGPB4P/u///g9z5sxBXV0dgMOHlw4cOJDuXSY1Y8YMnHPOOZg8eXK733cqEoE61C15rdkxf/liSEFvhhN1bl6PD39buLVJkQGA3Yf82FcVUCFV6jyBKN75bHuTIgMAVfVhbNxZrUKq1MUjYSxas6dJkQEAfyiOxWv3Ih6NqJCs84pV721aZABAkVG39HXEPdr425KC9c0WGQCoW/wqYnWHMpwoPVLI22yRAYDaxa9C8tdnOFF65GgQ3q8+bHbMu+ZDyJFghhOlWWY2bdqEfv364cknn8RTTz0Fj8cD4PD1ZebMmdOe+fDWW29h/fr1ePzxx1v189FoFD6fr9GtvciRYAtPkoJEvTZeUMeLSFzB1j3JX/xrt1ZlME36guE4Nu2sSTq+dkslQtGmBSHbBIIRrN1Wl3R87fZaBAPhDCai0M7k8xcje7cCcvb/XQH/zZpEvO4glEQsg2nSF69J/mFfDvshRbTxAUwKegEpkWQwASmU+Q/2aZWZWbNm4dprr8WOHTuQk/PjRMuf/exn+OKLL9ot3L59+3Dbbbfh9ddfb/Q4LXn88cfhdDobbu154T5BbHmKkWCytNtj0bEJAmA2JX9OXDZDBtOkTwBgNSfPajcboBezf4K5Xq+DrYX1sJn10Ouzfz2OJzpL8l3zOpMZ2T/J4DDRYk8+qBM1cWgGAHQ5LW8jBL1G3rP0xjaNd4S03lnWrl2Lm266qcnyLl26oKKios2hjvj6669RVVWFE044AXq9Hnq9HsuWLcPcuXOh1+shSVKT35kzZw68Xm/Dbd++Znaxpkm0OGAq7dPsmC7HBr2joN0ei44t156Ds0/qknR87LDkY9mkyG3Gz8b1SDo+ZWwPGPXZ/2Ztdzox/ZRuScfPP6U7z2rKMNugcUnH7CMmQ2yHeQ2ZkFM2EEhSWKz9xwAa+SCpdxVBlySrqesAiGZtnLSgM9ugdzU/yVfvKoJoyvwcv7TKjMlkavbwzfbt21FQ0H4b9EmTJmHz5s0oLy9vuI0aNQpXXXUVysvLIYpN/7hNJhMcDkejW3sRLQ4UnDcTotXVaLmgN6L40jnQ27XxxnC8MJhMmHZqb/Tu0vQ5vuXCQci1duhXj7UbURQxdkgJhvdtekbGRRP7IN9lViFVevqWOXHGyKanZ545qgR9Slv4dE0dQmd2wH3mL5ssN5b0huPEsyGatPG3JZtsKDxvJvCTS2AY3CXIPf1KGO1ulZKlRm93o+jSOU32XIi2XBROm9HyHqgsYnSXoHD6HU2Kmc5kQeEFs1Q5RTuts5muv/561NbW4p133oHb7camTZsgiiKmT5+OCRMmdOg1YE4//XTVzmY6IuGtQeTQTkT3fQdDfleYew6F3p53zMNQ1DFqa704UB3E2q1VcNqMGDOkBLlWPWwObbwxHFFZG0RVfRirvzmEHKMe44aVwGE1oiBXG586j6iv86DWH8fKTYcgCMC4oaVw20Xkuln21RD31UKOBBD6bg2kiB+W3ifC4C6GQWPXaIn6PEDUj9COdUj462DuMQTGgm4wutW7tkk6FCmBhK8W4T2bEK85AFPZQOSU9obeoZ3TywEgHg9D8dUhsncropV7YCrugZyuAyE4C2EwtM/hslS232mVGa/Xi4svvhjr1q2D3+9HaWkpKioqcPLJJ+Pjjz+G1dpxpydnQ5khIiKijtXhZeaIL7/8Ehs3bmy4Dozap043h2WGiIhIezrsOjNLlizBoEGDGubLjB8/Hr/+9a/xP//zPxg9ejQGDx6M5cuXp5+ciIiIKEUplZlnn30WN9xwQ7MNyel04qabbsIzzzzTbuGIiIiIjiWlMrNx40acffbZScfPOussfP31120ORURERNRaKZWZysrKFmcp6/V6VFdr4/LYREREdHxIqcx06dIF33zzTdLxTZs2oaREW6fJERERkbalVGZ+9rOf4b777kMk0vTL4sLhMB544AGce+657RaOiIiI6FhSOjW7srISJ5xwAkRRxC233IL+/fsDAL777js899xzkCQJ69evR1FR85c5VgNPzSYiItKeVLbfKV2ytqioCCtXrsTNN9+MOXPm4EgPEgQBU6ZMwXPPPZdVRYaIiIiOfylff7979+7497//jfr6euzcuROKoqBv377IzeWlyomIiCjz0v4yodzcXIwePbo9sxARERGlLK1vzSYiIiLKFiwzREREpGksM0RERKRpLDNERESkaSwzREREpGksM0RERKRpLDNERESkaSwzREREpGksM0RERKRpLDNERESkaSwzREREpGksM0RERKRpLDNERESkaSwzREREpGksM0RERKRpLDNERESkaSwzbRCOxiFJktox2iwUjh0X6xGJxhCPx9WO0WaRWALxhKx2jDaLxmKIxWJqx2izRDxxXKyHLEuQ49pfD0mSkIiG1Y5BR0mEg2pHgF7tAFoTjUuorg9hxcaD2L63HiV5Vpx5Uje4nTlwWE1qx0vJgeoA1m2twMYdNXA7cjDl5O5w2UwoyLWoHS0lB6sD2Px9Db7aUgm72YCzTu6OPIcJRXk2taOl5FBNANv3erBi4wGYDCImn9QNJXlWFOVZ1Y6WkuoaL/ZWBrBo3QEAwFmju6CsyI6CPIfKyVJTW+vFwdoQ/vPVfkTjCs4YWYw+XZ0oyHeqHS0lcX8dEp5K+Dd8BjkahKXvSTB3HwRDbrHa0VIS8dYCwXr4yz+DFKhHTo9hsPQeCWNeqdrROiUp6IcU8sC/eRni1XthKOwG+5DTIFpcEK32jOcRFEVRMv6oGeTz+eB0OuH1euFwtP3NdPveetz7wkqEo4mGZTqdgLt/fiJO7F8Ac46xzY+RCT8c8uG3L3wJb6DxJ7X/d8FQnDykGHkubRSaA9UBPPDiKlTWhRotv2hiH/xsXDcUujP/okpHRU0Qj73yFXYf9DVafvoJXXHV2QNQrJFCU13rw9x3NqJ8Z12j5Sf0y8MtFw9FQZ42ikBtrRevfLwNSzccarS8T1cH7vnFiZopZgl/Pbxr3od3zYeNlutzi1F8+b0wuktUSpaaqK8O4e9Wom7RvEbLRasLxVc9CFNBmUrJOqd4PILE/u049PajgPTjtlAQDSi+7B7ouw6EwWBo8+Oksv3mYaYUVNQG8Ke3NjQqMgAgywr+9NYG1Pq0sQu3uj6Il97/pkmRAYAX39uMYFQbh5x8/hD+uXh7kyIDAO8u3QlfSBvrEUtIWLxub5MiAwCfr9+Pilr1d+G21re7apsUGQBYv70W2/bUq5AoPfurQ02KDADs3O/D8vL9iMcTzfxW9pH8tU2KDAAk6ivgXf0epFhEhVRpiAZRt+jlJouloAd1n72CqLfp3xx1HMVXh6oP/tSoyACAIsVR9cFcKP7qjGdimUlBIJzA3kp/s2ORmITKOm1sdEJRCZt2Nv/HJiuHN0ha4I9I+GLDgaTjK8qTj2WTmvowlqzbl3R80Zq9mth41tb58NHq5OuxcPV+1NU3//rJJpFIBJ+sSb4en6w5CI83kMFE6Qt8uyL52DfLIQc8mQvTBuE9mwE0fxAhvKsciDX9QEMdRw77ISX525EC9ZBDmX99sMykQJZanpQZi2tjT4AsK2jp4GIklv0bTgCAAiRaeE4iMW08HwoUxOLJ1yMal5CQs/9osCK3vB6xuHTM11A2kGUFkWM8H1o5OC/Ho0nHlEQcSpKCkG2UREt7vRVAyf6/q+OJIrf83qrImd+GsMykwGoxwmVvfpKvTiega6E25mfkGEV0L06edVjv/AymSZ/JoMOIvgVJx8cO1cZ8AKfVhNGDipKOnzKiFGZT248/dzSHw4xThiR/PiYMK4TLlf1zfywWM04fkfz5GDe4AHaNTPa3Djg56Zi51wjoTNqYG2fuPiTpmLGoJ2DIyWAaEq1OCIbmXwOCIQeiNfNz41hmUlDoMuP685t/UU0/rTdsFm2cHFaSb8MN04dCpxOajE0Y2QU2szbWIz/XimvOGQSTQWwyNrR3HopyzSqkSp3NYsQFp/eBzdy0sPQocaB/t1wVUqXOaDRiwsgy5LuablgKcs0YO6wL9Hpt/G0N7OFG9+KmZ8M5rEacN6EPzBZt/G0Z3KXIKRvUZLlgMMF9+pXQq7DRSYvZAevAsU2X60S4z/wlTLmFmc/UiQlmO3JPu6LZMffEKyGaeTZTu2vvs5lqvWEcrAnijf98hz0HfSh0W3DRxD4Y0N2NQrc2PuUAQL0/hOr6KN78z3fYtrceLnsOzju1F0b2K9DUqcCBYAjV3jje+Ww7Nu6ohs1sxNnjemD80BJNrYckSThYE8KCz3dizbcVMBlEnDGqDJNGd0NJvnbWAwAqqn3495e78Hl5BQRBwMSRxTh7bE8UF2jjDKAjqmp8WLJ2L/6z7gDiCRnjhhRi+ml9UOi2aqaUAUDcU4Xg1pXwrf8UcjQEc89hyB1/MfTuEuj02b/H74hYfRXCuzbAt/YjSCEvTF36I/fUyyA4C2FS4VTgzi7uqUKsZh88y/+JeN0hGPJK4TrlYhjzusKQm3zPZipS2X6zzKSpxhNCNC5Br9NpaqP5U7WeECIxCYIAlBZo9w2h3hdCKHJ4PQpzzZra2BwtEIrBG4xBAJCfa4ZR33SvkxaEwhH4A4fPlLFbzbBYtHFY5qfisRjqvYcnl9qsJlg0skfmp2RZhuSrAWQZgsUGfY62rsF0tEhdBQRFAQw5MDm0sdfyeBb3VEGR4hBEPQyu9ikxR7DMHKWjygwRERF1HF5nhoiIiDoNlhkiIiLSNJYZIiIi0jSWGSIiItI0lhkiIiLSNJYZIiIi0jSWGSIiItI0lhkiIiLSNJYZIiIi0jSWGSIiItI0lhkiIiLSNJYZIiIi0jSWGSIiItI0lhkiIiLSNJYZIiIi0jSWGSIiItI0lhkiIiLSNJYZIiIi0jSWGSIiItI0lhkiIiLSNJYZIiIi0jSWGSIiItI0lhkiIiLSNJYZIiIi0jSWGSIiItI0lhkiIiLSNJYZIiIi0jS92gGO5fHHH8f8+fPx3XffwWw2Y9y4cXjyySfRv39/1TJV1gURiiRQ6wnDYTPBbjGgJN+mWp50BcNxeAJR1HrDsOYY4LKbkOc0qx0rZVX1IUSiCVR7wjCb9HBaTci1mWCxGNSOlpJaTwihqIQaTxh6UQe3wwSH1Qi71aR2tJR4/RH4w3HUeiKAAOQ5c2Az6+Gya+tvKxpPoNYTQa0vgoQko8BlhstmhM2iredDlhNIeKohBT1QYhHonQXQmR3QWx1qR0tZdY0HnmAcoXAceS4LnGYd7E7trcfxQgp6D99CXogWJ0Tr4Zsasr7MLFu2DDNmzMDo0aORSCRwzz334KyzzsKWLVtgtVoznqeiNojn/rkR5TuqG5Z1K7Zj9i9Go6zInvE86arzRTDvw2/x+fr9DcsKc824//qT0b1YO28OlbVBLFj2PT5euRuycniZy27Cb64ehZ7FNlitOeoGbKWK2gA+X38Aby/ahoR0eEWsZgPuuHwk+pU5keu0qJywdarqgtiwvRovvfcNonEJAGAyirhp+lAM75eHwlxtlP5AOI7NO2vwp7fWIxhJAAD0og5XTumPSaPK4NZI6ZfjUUQP7kTl/Kcgh3yHFwo6OEZNhfPk82Bw5KsbsJUkScLeQ148/PI6VNeHAQCCAEwcWYJrpg6A262d96zjRdxbjar5zyB6cHvDMlNpPxReOAsGZ0HG82T9YaZPPvkE1157LQYPHozhw4fj5Zdfxt69e/H1119nPEuNJ4x5C79tVGQAYG+FH4+9/BUO1QQynikd8YSED5fvalRkAKCqPox7n1/Z8GaR7RKJBNZsqcBHX/5YZADA44/iwf9bjfpgXL1wKdp9wIfXP/muocgAh/ecPf7KWnhD2lmPGm8E//vPjQ1FBgCiMQlz3ylHrTeqYrLU1NSH8MSraxuKDAAkJBmv/nsrdh7wqpgsNQlfDSreeuTHIgMAigzf2o8Q2rFOvWApqq0L4N4X1zR6b1IUYMn6Q/ho5R7EozEV03U+UsiHqvf+1KjIAED04HZUf/BnSGF/xjNlfZn5Ka/38BuJ2+1udjwajcLn8zW6tZdQJI7Vmw81O7a/KgBPQBsvqHp/FAtX7Gp2zBOIYl9l+/0/60hV9RHMX7qz2bFoTEL59upmx7JNRW0A/1yyo9kxSVbw2dq9kCSp2fFsUu8LYcHnzT8fAPDesu/h8WV/UY5LMj5d8wPkoxvyUf65eDtqvdm/HgAQ2rkeSqL59yXvqvcQr6/McKL07Dnkgy/Y/HosXLUPdb5QhhN1blLIh+j+rc2ORfZ+CymY+cKvqTIjyzJuv/12jB8/HkOGDGn2Zx5//HE4nc6GW1lZWbs9fiiaQJL3NwDQzBtcLC4hEku+cTxYE8xgmvTJClDrjSQd31uhjVImSQoq65K/GR+sCiIcTSQdzxaRmISK2uTrUVkbQjiW/esRiydwoDr5a6CiNoRYPPvLJQDEqvclHUt4qwFFzmCa9B2oTv5JPxRJIJ7QxnocL+Roy+XxWOMdQVNlZsaMGfjmm2/w1ltvJf2ZOXPmwOv1Ntz27Uv+Yk6VJccAvSgkHS/K1ca8BpNBD5s5+eRYrcyZ0emAkrzk86b6lOVmME36DHpdi/OtenVxamLSqdWkR/fi5OvRvcQBS07WT9NDjkGPXl2Svwa6FdthNmX/egBATmmfpGOGvC6ATsxgmvT1KEk+qdRhNcKo19SmTPN0OS3PfTvWeEfQzF/ALbfcgoULF2Lp0qXo2rVr0p8zmUxwOByNbu3FbtZj0uhuzY71LXPBbjW222N1JLfDhEsm92t2rMhtQWlB5idWp6M034YrpjR/VpvDasTgXnkZTpSeQrcVV5zV/HqYjCJOOyH533s2cdjNmH56H+ia6fs6nYDzJ/SC05b9E2dFUYczRnVLuoG84sz+cNm1MbE8p/uQpBuW3AmXweAqzHCi9HQttKEgt/m/nUsn9oRbIxPLjxei1QFLv5OaHbP0P0mVM5qyvswoioJbbrkFCxYswJIlS9CzZ0/VsuQ6zLjkjL6YPLobxKPesUf0K8BdPz8RxS3sJcgmh9+sy3Dp5H4wHPWGPaB7Lh6+aaymTs8e1NONa88d1OiTcrdiO35341h0KdDOG1yx24zbLhsB+1GnkxfnWfDQDWORZ9dGSQYAp02Pe649Cbn2H/ckuR05+O0vT0Kuhtaj0G3GQzeORZH7x72tDqsRd1wxEmVF2vm70ucWo+SqB2DI/7EQC0Yz3JOugalsoIrJUlOQ78TDN4xB3zJXwzKjXofLzuiFCcNLoddrY0/Z8ULMsSH/7OthHTgOEP67DRF0sA4ch/wpN0DMyfy2UFAUpYVZIOr79a9/jTfeeAPvv/9+o2vLOJ1OmM3H3uj6fD44nU54vd5220tT6wsjFE4gEI7DbNLDkiOiMFcbReZosbiEOn8EwVAcRoMIp80Ih8auaQIAgVAUnkAM/lAcRr0Olhy9Jq/7EwpFUR+MwR+MQxQF2MzavH5RPB5HlSeCQCgOQRBgM+tR4MqBwaCt6/4Ahy/F4A/FIMsK7FYjClyWRh8AtCLuqYYcCUBJxKGz2KC350Nn0E65PMJT54UvIiEWk2CzGOGyG5HTiu0AdQwpGoIc9EKOhqEzmaGzOiGa2m+6RSrb76wvM4LQ/ByVefPm4dprrz3m73dEmSEiIqKOlcr2O+v3zWV51yIiIiKVaW9/KREREdFRWGaIiIhI01hmiIiISNNYZoiIiEjTWGaIiIhI01hmiIiISNNYZoiIiEjTWGaIiIhI01hmiIiISNNYZoiIiEjTWGaIiIhI01hmiIiISNNYZoiIiEjTWGaIiIhI01hmiIiISNNYZoiIiEjTWGaIiIhI01hmiIiISNNYZoiIiEjTWGaIiIhI01hmiIiISNNYZoiIiEjTWGaIiIhI01hmiIiISNNYZoiIiEjTWGaIiIhI0/RqB9CqgzUByLICnSAgz5EDk0mb/ysP1QQhyTIEQUCu3QRLjkHtSGmpqA0iIcnQCQLsFgPsVpPakdJSVR9EPCEDEGA1iXA5zGpHSkuNJ4xoXAIA5BhF5Dm1uR71vhBCURmAAqOoQ4HbqnaktMQTEryBKGQZMJv0sFuNakfq1BRFhuSvhyLLEPQG6G0utSOlLeGvgyIlIIh66O1u1XJocwusosraIL7bW483PvkOB2uCcNlNOH9Cb5w6vBRFedp5o6uqDWFftR8vL9yCPYd8sJoNmDq2O6ac3APFGlqPWm8IFbVhzFv4Lbb9UI8co4hJo7vh/NN6o0RD6+ELhlFVH8XLC7dg085qiDodTh1RisvO7I8uBTa147VaLBbDodoIXvt4K9ZurQQAnDSoCFdPHYhuxQ6V06Vmf5Ufby3aji83HoQkyxjetwDXnjMIxbk5sFpz1I7XajWeMBZ8vhP/WfMDojEJg3q68avzhqBHiQNGg6h2vE4nEfAg8M0X8K5+D1LQC4O7FO4zrkZOt0EQzdp5rUtBH4I716H+i7ch+WogOvKRO+EyWPuOgmjJ/GtdUBRFyfijZpDP54PT6YTX64XD0bb/wYFwDEvX7ceL721uMjZpVBmunNIfhRr55LZy80E8/vLaJsuH983HLZeM0Eyh2bKrFnOe/xKy3PjPuEeJA/dcOxol+dp4c9h90Iu7/vQFYgm50fLCXDMevmkcSjVSaPZX+XH33OUIhOONltstBvz+1gnoWqiN9ThYHcC9L6xEtSfcaLnJIOKp205FjxKnSslSU+sN44GXVuGHQ/5Gy3U6AU/NPBV9y3JVStY5SeEAaj97GYFNS5uMFZw7A7ahp0HQZX/BlONReFa+B8+Kd5qMuU69FK6xF0BnaPvev1S235wzkwKPP4rX//Nds2NLvt6HcFTKcKL0HKwJYN6H3zY7tnFHDbyBaIYTpaeyLoh5H33bpMgAwJ5DPuyvCqiQKnV1vhDe+WxbkyIDAFX1YWzcWa1CqtSFInF8uvqHJkUGAPyhOBav/QGRSEyFZKlbv62qSZEBgGhcwr+W7ES9L6RCqtTtOeRrUmQAQJYVzPvwW/hD2ng+jhdSyNtskQGA2sWvQvLXZzhReqSAB55V85sd86ycDymY+fVgmUlBMBxHsJk3agBQFGhm4xmJSqioTf5m/O2uugymSV8ioeC7PclfNEcOc2S7UETCpp21ScfXbqlEMJz9BdMbiGLD9uTFa8P2atQHs3/j6QtGsK6Fv51NO6oRjGjjg8tX31YkHftmVy0iGvkAdryI1xxIOiaH/ZAi2tiGSCEvICWSDCYgBX2ZDQSWmZQY9S3v/rOZtTF5Vq/XQacTko47bBqZHCgcnsyYjFMjkxx1AmBt4W/HbjZAf4y/vWxgEMUWXwNWswFGffa/5RhEXYvrYbMY0cLLJ6u47MknwltMeggaWY/jhS7H0uK4oNfGNkQQW86pxnpk/ztLFjHn6NG3zNXsmM1sQJ5LG5MCLSY9ThpU1OyYXtShfzdtHEd32QyYPLos6fj4YaUZTJO+wlwzfjauR9LxKWN7wGTI/rn6+blmnHNKz6Tj547viTxny2/m2cCcY8TZY3skHZ86tgdKC+yZC9QGpwzvknTsnFN6tVh2qP3pXUXQmZp/DZi6DoBo1sYkedHqhN6VZBviKlJlAjDLTAqK86yYedmIJm8AJoOIOdeORp5dG2Um32XGtecMbnK2j04n4K6rToRFI3uYrGYTzpvQG727NJ2M+f8uGAprTvYXAADQ6/U4eUgJhvfNbzJ20cQ+yHNoZ4PTt6sLE0Y03YBOPLErepZqY9IsABTkmjH9tN5Nlo/sV5D0g0A2ynPm4NcXDWuyvF83F342rgf0IjcBmaS3u1F06RwI+sZ7jUVbLgqnzYBo0UZJ1tvdKLro7ibFTGeyoOji/1HlFG2ezZSGA9UB7Nhbj+9+qEfXQhtG9CuAw2aEw6KdjQ4AHKwJYs9BLzZ/X4N8lxmjBxXDniMiVwOfno92qCaIgzUBrNtaCafNhJOHFMNq0mvumiCHagOoqQ9j9TcVyDHqMW5YCaxmPYrztHEG0BEVtUF4/FGs3HwIggCMG1oCp82kmTPkjqisC8AfSuDLTQcRj0s4eUgJ8l05mns+QpE46nwRrPmmAt5gDCcNKkJpgQ1uhzY+fB1vFCmBhK8W4T2bEK85AFPZQOSU9obe0fTDTDZTFBkJbw0i+79D7NAuGEt6IafrAOidBRDa6fhlKttvlhkiIiLKOjw1m4iIiDoNlhkiIiLSNJYZIiIi0jSWGSIiItI0lhkiIiLSNJYZIiIi0jSWGSIiItI0lhkiIiLSNJYZIiIi0jSWGSIiItI0lhkiIiLSNG18rXAbHPnqKZ/Pp3ISIiIiaq0j2+3WfIXkcV9m/H4/AKCsrEzlJERERJQqv98Pp9PZ4s8c99+aLcsyDh48CLvd3m5fS3688fl8KCsrw759+/jN4lmAz0d24fORXfh8ZJeOfD4URYHf70dpaSl0upZnxRz3e2Z0Oh26du2qdgxNcDgcfHPIInw+sgufj+zC5yO7dNTzcaw9MkdwAjARERFpGssMERERaRrLDMFkMuGBBx6AyWRSOwqBz0e24fORXfh8ZJdseT6O+wnAREREdHzjnhkiIiLSNJYZIiIi0jSWGSIiItI0lplO6vHHH8fo0aNht9tRWFiI6dOnY9u2bWrHov964oknIAgCbr/9drWjdGoHDhzAz3/+c+Tl5cFsNmPo0KFYt26d2rE6JUmScN9996Fnz54wm83o3bs3Hn744VZd6p7a7osvvsC0adNQWloKQRDw3nvvNRpXFAX3338/SkpKYDabMXnyZOzYsSNj+VhmOqlly5ZhxowZWL16NRYtWoR4PI6zzjoLwWBQ7Wid3tq1a/HXv/4Vw4YNUztKp1ZfX4/x48fDYDDg448/xpYtW/D0008jNzdX7Wid0pNPPonnn38e//u//4utW7fiySefxO9//3v8+c9/VjtapxAMBjF8+HA899xzzY7//ve/x9y5c/HCCy9gzZo1sFqtmDJlCiKRSEby8WwmAgBUV1ejsLAQy5Ytw4QJE9SO02kFAgGccMIJ+Mtf/oJHHnkEI0aMwLPPPqt2rE5p9uzZ+PLLL7F8+XK1oxCAc889F0VFRfjb3/7WsOyiiy6C2WzGP/7xDxWTdT6CIGDBggWYPn06gMN7ZUpLS3HnnXfirrvuAgB4vV4UFRXh5ZdfxuWXX97hmbhnhgAc/sMDALfbrXKSzm3GjBk455xzMHnyZLWjdHoffPABRo0ahUsuuQSFhYUYOXIkXnrpJbVjdVrjxo3D4sWLsX37dgDAxo0bsWLFCkydOlXlZLR7925UVFQ0et9yOp0YM2YMVq1alZEMx/13M9GxybKM22+/HePHj8eQIUPUjtNpvfXWW1i/fj3Wrl2rdhQCsGvXLjz//POYNWsW7rnnHqxduxYzZ86E0WjENddco3a8Tmf27Nnw+XwYMGAARFGEJEl49NFHcdVVV6kdrdOrqKgAABQVFTVaXlRU1DDW0VhmCDNmzMA333yDFStWqB2l09q3bx9uu+02LFq0CDk5OWrHIRwu+aNGjcJjjz0GABg5ciS++eYbvPDCCywzKnjnnXfw+uuv44033sDgwYNRXl6O22+/HaWlpXw+iIeZOrtbbrkFCxcuxNKlS/nt4ir6+uuvUVVVhRNOOAF6vR56vR7Lli3D3LlzodfrIUmS2hE7nZKSEgwaNKjRsoEDB2Lv3r0qJerc7r77bsyePRuXX345hg4diquvvhp33HEHHn/8cbWjdXrFxcUAgMrKykbLKysrG8Y6GstMJ6UoCm655RYsWLAAS5YsQc+ePdWO1KlNmjQJmzdvRnl5ecNt1KhRuOqqq1BeXg5RFNWO2OmMHz++yeUKtm/fju7du6uUqHMLhULQ6RpvskRRhCzLKiWiI3r27Ini4mIsXry4YZnP58OaNWswduzYjGTgYaZOasaMGXjjjTfw/vvvw263NxzXdDqdMJvNKqfrfOx2e5P5SlarFXl5eZzHpJI77rgD48aNw2OPPYZLL70UX331FV588UW8+OKLakfrlKZNm4ZHH30U3bp1w+DBg7FhwwY888wzuO6669SO1ikEAgHs3Lmz4d+7d+9GeXk53G43unXrhttvvx2PPPII+vbti549e+K+++5DaWlpwxlPHU6hTglAs7d58+apHY3+67TTTlNuu+02tWN0ah9++KEyZMgQxWQyKQMGDFBefPFFtSN1Wj6fT7ntttuUbt26KTk5OUqvXr2U3/72t0o0GlU7WqewdOnSZrcZ11xzjaIoiiLLsnLfffcpRUVFislkUiZNmqRs27YtY/l4nRkiIiLSNM6ZISIiIk1jmSEiIiJNY5khIiIiTWOZISIiIk1jmSEiIiJNY5khIiIiTWOZISIiIk1jmSEiIiJNY5kh6sQEQcB7772ndow2e/DBBzFixIgWf+b000/H7bff3qr7+/zzzyEIAjweT5uzEVHHY5khOo5VVFTg1ltvRa9evWAymVBWVoZp06Y1+kK4bHakVLR0+/zzz1t1X/Pnz8fDDz/csYGJSBX8okmi49SePXswfvx4uFwu/OEPf8DQoUMRj8fxn//8BzNmzMB3332ndsRjGjduHA4dOtTw79tuuw0+nw/z5s1rWOZ2u1tVaNxud0dEJKIswD0zRMepX//61xAEAV999RUuuugi9OvXD4MHD8asWbOwevXqJj/f3KGV8vJyCIKAPXv2AABefvlluFwuLFy4EP3794fFYsHFF1+MUCiEV155BT169EBubi5mzpwJSZIa7qdHjx54+OGHccUVV8BqtaJLly547rnnjrkORqMRxcXFDTez2QyTydRomdFobPj51157DT169IDT6cTll18Ov9/fMPbTw0zRaBS/+c1vUFZWBpPJhD59+uBvf/tbszlCoRCmTp2K8ePHw+PxYM+ePRAEAfPnz8fEiRNhsVgwfPhwrFq1qtHvrVixAqeeeirMZjPKysowc+ZMBIPBhvG//OUv6Nu3L3JyclBUVISLL764Yexf//oXhg4dCrPZjLy8PEyePLnR7xLRj1hmiI5DdXV1+OSTTzBjxgxYrdYm4y6XK+37DoVCmDt3Lt566y188skn+Pzzz3HBBRfg3//+N/7973/jtddew1//+lf861//avR7f/jDHzB8+HBs2LABs2fPxm233YZFixalneOnvv/+e7z33ntYuHAhFi5ciGXLluGJJ55I+vO/+MUv8Oabb2Lu3LnYunUr/vrXv8JmszX5OY/HgzPPPBOyLGPRokWN/t/99re/xV133YXy8nL069cPV1xxBRKJREOes88+GxdddBE2bdqEt99+GytWrMAtt9wCAFi3bh1mzpyJ3/3ud9i2bRs++eQTTJgwAQBw6NAhXHHFFbjuuuuwdetWfP7557jwwgvB7wUmSiJj389NRBmzZs0aBYAyf/78Fn8OgLJgwQJFURRl6dKlCgClvr6+YXzDhg0KAGX37t2KoijKvHnzFADKzp07G37mpptuUiwWi+L3+xuWTZkyRbnpppsa/t29e3fl7LPPbvTYl112mTJ16tSU1uuaa65Rzj///CbLH3jgAcVisSg+n69h2d13362MGTOm4d+nnXaacttttymKoijbtm1TACiLFi1q9nGO/L/YunWrMmzYMOWiiy5SotFow/ju3bsVAMr//d//NSz79ttvG35HURTlV7/6lXLjjTc2ut/ly5crOp1OCYfDyrvvvqs4HI5GmY/4+uuvFQDKnj17jv0/hYgU7pkhOg4pHfgJ3mKxoHfv3g3/LioqQo8ePRrt1SgqKkJVVVWj3xs7dmyTf2/durXdcvXo0QN2u73h3yUlJU0yHFFeXg5RFHHaaae1eJ9nnnkm+vTpg7fffrvR4awjhg0b1ujxADQ85saNG/Hyyy/DZrM13KZMmQJZlrF7926ceeaZ6N69O3r16oWrr74ar7/+OkKhEABg+PDhmDRpEoYOHYpLLrkEL730Eurr61P7H0LUibDMEB2H+vbtC0EQUprkq9Mdfjs4ugjF4/EmP2cwGBr9WxCEZpfJspxK5DZLJYPZbG7VfZ5zzjn44osvsGXLlmM+piAIANDwmIFAADfddBPKy8sbbhs3bsSOHTvQu3dv2O12rF+/Hm+++SZKSkpw//33Y/jw4fB4PBBFEYsWLcLHH3+MQYMG4c9//jP69++P3bt3tyo3UWfDMkN0HHK73ZgyZQqee+65ZieNNnf9lIKCAgBodPZQeXl5u2X66aTj1atXY+DAge12/6kYOnQoZFnGsmXLWvy5J554Atdccw0mTZqUtNAkc8IJJ2DLli3o06dPk9uRvTx6vR6TJ0/G73//e2zatAl79uzBkiVLABwuR+PHj8dDDz2EDRs2wGg0YsGCBemtMNFxjmWG6Dj13HPPQZIknHTSSXj33XexY8cObN26FXPnzm1yyAcA+vTpg7KyMjz44IPYsWMHPvroIzz99NPtlufLL7/E73//e2zfvh3PPfcc/vnPf+K2225rt/tPRY8ePXDNNdfguuuuw3vvvYfdu3fj888/xzvvvNPkZ5966ilcddVVOOOMM1La0/Wb3/wGK1euxC233ILy8nLs2LED77//fsME4IULF2Lu3LkoLy/HDz/8gFdffRWyLKN///5Ys2YNHnvsMaxbtw579+7F/PnzUV1drVr5I8p2vM4M0XGqV69eWL9+PR599FHceeedOHToEAoKCnDiiSfi+eefb/LzBoMBb775Jm6++WYMGzYMo0ePxiOPPIJLLrmkXfLceeedWLduHR566CE4HA4888wzmDJlSrvcdzqef/553HPPPfj1r3+N2tpadOvWDffcc0+zP/vHP/4RkiThjDPOwOeff97s/JmfGjZsGJYtW4bf/va3OPXUU6EoCnr37o3LLrsMwOEzyubPn48HH3wQkUgEffv2xZtvvonBgwdj69at+OKLL/Dss8/C5/Ohe/fuePrppzF16tR2/X9AdLwQlI6cKUhEhMN7Qm6//fZWf50AEVEqeJiJiIiINI1lhohU9frrrzc6ffno2+DBg9WOR0QawMNMRKQqv9+PysrKZscMBgO6d++e4UREpDUsM0RERKRpPMxEREREmsYyQ0RERJrGMkNERESaxjJDREREmsYyQ0RERJrGMkNERESaxjJDREREmsYyQ0RERJr2/wGU/QIWEB7a3AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x = X1['Clump_Thickness'], y = X1['Cell_Size_Uniformity'], hue = y1, palette = \"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chosen Algorithm\n",
    "\n",
    "For this assignment, we decided to use KNN. [[more about K-Nearest Neighbors]](#knnk-nearest-neighbors)\n",
    "\n",
    "In our initial approach, we will implement the algorithm without modifications and analyze the outcomes. Sencondly, we aim to enhance these results by implementing a modified algorithm for comparison. We will adjust the number of k-neighbors, explore different distance methods, and experiment with various features to achieve this improvement.\n",
    "\n",
    "[[go back to the top]](#table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "[[go back to the topic]](#chosen-algorithm)\n",
    "\n",
    "The metrics.py file contains various performance evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "\n",
    "EPS = 1e-15\n",
    "\n",
    "\n",
    "def unhot(function):\n",
    "    \"\"\"Convert one-hot representation into one column.\"\"\"\n",
    "\n",
    "    def wrapper(actual, predicted):\n",
    "        if len(actual.shape) > 1 and actual.shape[1] > 1:\n",
    "            actual = actual.argmax(axis=1)\n",
    "        if len(predicted.shape) > 1 and predicted.shape[1] > 1:\n",
    "            predicted = predicted.argmax(axis=1)\n",
    "        return function(actual, predicted)\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def absolute_error(actual, predicted):\n",
    "    return np.abs(actual - predicted)\n",
    "\n",
    "\n",
    "@unhot\n",
    "def classification_error(actual, predicted):\n",
    "    return (actual != predicted).sum() / float(actual.shape[0])\n",
    "\n",
    "\n",
    "@unhot\n",
    "def accuracy(actual, predicted):\n",
    "    return 1.0 - classification_error(actual, predicted)\n",
    "\n",
    "\n",
    "def mean_absolute_error(actual, predicted):\n",
    "    return np.mean(absolute_error(actual, predicted))\n",
    "\n",
    "\n",
    "def squared_error(actual, predicted):\n",
    "    return (actual - predicted) ** 2\n",
    "\n",
    "\n",
    "def squared_log_error(actual, predicted):\n",
    "    return (np.log(np.array(actual) + 1) - np.log(np.array(predicted) + 1)) ** 2\n",
    "\n",
    "\n",
    "def mean_squared_log_error(actual, predicted):\n",
    "    return np.mean(squared_log_error(actual, predicted))\n",
    "\n",
    "\n",
    "def mean_squared_error(actual, predicted):\n",
    "    return np.mean(squared_error(actual, predicted))\n",
    "\n",
    "\n",
    "def root_mean_squared_error(actual, predicted):\n",
    "    return np.sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "\n",
    "def root_mean_squared_log_error(actual, predicted):\n",
    "    return np.sqrt(mean_squared_log_error(actual, predicted))\n",
    "\n",
    "\n",
    "def logloss(actual, predicted):\n",
    "    predicted = np.clip(predicted, EPS, 1 - EPS)\n",
    "    loss = -np.sum(actual * np.log(predicted))\n",
    "    return loss / float(actual.shape[0])\n",
    "\n",
    "\n",
    "def hinge(actual, predicted):\n",
    "    return np.mean(np.max(1.0 - actual * predicted, 0.0))\n",
    "\n",
    "\n",
    "def binary_crossentropy(actual, predicted):\n",
    "    predicted = np.clip(predicted, EPS, 1 - EPS)\n",
    "    return np.mean(-np.sum(actual * np.log(predicted) + (1 - actual) * np.log(1 - predicted)))\n",
    "\n",
    "\n",
    "# aliases\n",
    "mse = mean_squared_error\n",
    "rmse = root_mean_squared_error\n",
    "mae = mean_absolute_error\n",
    "\n",
    "\n",
    "def get_metric(name):\n",
    "    \"\"\"Return metric function by name\"\"\"\n",
    "    try:\n",
    "        return globals()[name]\n",
    "    except Exception:\n",
    "        raise ValueError(\"Invalid metric function.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distances\n",
    "[[go back to the topic]](#chosen-algorithm)\n",
    "\n",
    "The inicial github file provides these functions: \n",
    "\n",
    "- the Euclidean distance \n",
    "\n",
    "- the L2 distance matrix for a set of points in a dataset.\n",
    "  \n",
    "But, as said above, we'll explore different distance methods, like:\n",
    "- Euclidean distance (features)\n",
    "- Cosine Similarity\n",
    "- Manhattan Distance\n",
    "- Jaccard Distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidian Distance\n",
    "[[go back to the topic]](#distances)\n",
    "\n",
    "This function is designed to calculate the distance between two individual points p1 and p2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "def euclidean_distance(a, b):\n",
    "    if isinstance(a, list) and isinstance(b, list):\n",
    "        a = np.array(a)\n",
    "        b = np.array(b)\n",
    "\n",
    "    return math.sqrt(sum((a - b) ** 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 Distance\n",
    "[[go back to the topic]](#distances)\n",
    "\n",
    "\n",
    "The function l2_distance(X) calculates the pairwise L2 or Euclidean distances between rows of a matrix X. This matrix X is expected to be a two-dimensional NumPy array where each row represents a point in a multidimensional space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_distance(X):\n",
    "    sum_X = np.sum(X * X, axis=1)\n",
    "    return (-2 * np.dot(X, X.T) + sum_X).T + sum_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidian Distance (features)\n",
    "[[go back to the topic]](#distances)\n",
    "\n",
    "This function is designed to calculate the Euclidean distances between a single point p1 and multiple points p2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_features(p1, p2):\n",
    "    temp = p1 - p2[:, np.newaxis]\n",
    "    euclid_dist = np.sqrt(np.sum(temp ** 2, axis=-1))\n",
    "    return euclid_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity\n",
    "[[go back to the topic]](#distances)\n",
    "\n",
    "The function cosine_similarity(row1, row2) calculates the cosine similarity between two vectors represented by row1 and row2. Cosine similarity measures the cosine of the angle between two vectors in a multi-dimensional space, providing an indication of how similar the vectors are in terms of orientation, regardless of their magnitude.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(row1, row2):\n",
    "    norm1 = norm(row1)\n",
    "    norm2 = norm(row2)\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0  # avoid zero division\n",
    "    simi = np.dot(row1, row2) / (norm1 * norm2)\n",
    "    return simi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manhattan Distance\n",
    "[[go back to the topic]](#distances)\n",
    "\n",
    "The function calculates the distance between two vectors a and b.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(a,b):\n",
    "    return sum(abs(val1-val2) for val1,val2 in zip(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard Distance\n",
    "[[go back to the topic]](#distances)\n",
    "\n",
    "The function computes the Jaccard distance between two lists, which represent sets of elements. The Jaccard distance is a measure of dissimilarity between two sets based on the size of their intersection divided by the size of their union.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1)+len(list2))-intersection\n",
    "    return float(intersection)/union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base\n",
    "[[go back to the top]](#table-of-contents)\n",
    "\n",
    "Here, we present the implementation of the original algorithm without any modifications.\n",
    "\n",
    "This BaseEstimator python script is used for creating estimators. Includes methods for configuring input data, helping models, and making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class BaseEstimator:\n",
    "    y_required = True\n",
    "    fit_required = True\n",
    "\n",
    "    def _setup_input(self, X, y=None):\n",
    "        \"\"\"Ensure inputs to an estimator are in the expected format.\n",
    "\n",
    "        Ensures X and y are stored as numpy ndarrays by converting from an\n",
    "        array-like object if necessary. Enables estimators to define whether\n",
    "        they require a set of y target values or not with y_required, e.g.\n",
    "        kmeans clustering requires no target labels and is fit against only X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like\n",
    "            Feature dataset.\n",
    "        y : array-like\n",
    "            Target values. By default is required, but if y_required = false\n",
    "            then may be omitted.\n",
    "        \"\"\"\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            X = np.array(X)\n",
    "\n",
    "        if X.size == 0:\n",
    "            raise ValueError(\"Got an empty matrix.\")\n",
    "\n",
    "        if X.ndim == 1:\n",
    "            self.n_samples, self.n_features = 1, X.shape\n",
    "        else:\n",
    "            self.n_samples, self.n_features = X.shape[0], np.prod(X.shape[1:])\n",
    "\n",
    "        self.X = X\n",
    "\n",
    "        if self.y_required:\n",
    "            if y is None:\n",
    "                raise ValueError(\"Missed required argument y\")\n",
    "\n",
    "            if not isinstance(y, np.ndarray):\n",
    "                y = np.array(y)\n",
    "\n",
    "            if y.size == 0:\n",
    "                raise ValueError(\"The targets array must be no-empty.\")\n",
    "\n",
    "        self.y = y\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self._setup_input(X, y)\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            X = np.array(X)\n",
    "\n",
    "        if self.X is not None or not self.fit_required:\n",
    "            return self._predict(X)\n",
    "        else:\n",
    "            raise ValueError(\"You must call `fit` before `predict`\")\n",
    "\n",
    "    def _predict(self, X=None):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original KNN\n",
    "[[go back to the topic]](#base)\n",
    "\n",
    "This Python code defines a base framework and specific implementations for the k-nearest neighbors (KNN) algorithm, with a classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "\n",
    "class KNNBase(BaseEstimator):\n",
    "    def __init__(self, k=7, distance_func=euclidean_distance):\n",
    "        \"\"\"Base class for Nearest neighbors classifier and regressor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int, default 5\n",
    "            The number of neighbors to take into account. If 0, all the\n",
    "            training examples are used.\n",
    "        distance_func : function, default euclidean distance\n",
    "            A distance function taking two arguments. Any function from\n",
    "            scipy.spatial.distance will do.\n",
    "        \"\"\"\n",
    "\n",
    "        self.k = None if k == 0 else k  # l[:None] returns the whole list\n",
    "        self.distance_func = distance_func\n",
    "\n",
    "    def aggregate(self, neighbors_targets):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def _predict(self, X=None):\n",
    "        predictions = [self._predict_x(x) for x in X]\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict_x(self, x):\n",
    "        \"\"\"Predict the label of a single instance x.\"\"\"\n",
    "\n",
    "        # compute distances between x and all examples in the training set.\n",
    "        distances = (self.distance_func(x, example) for example in self.X )\n",
    "\n",
    "        # Sort all examples by their distance to x and keep their target value.\n",
    "        neighbors = sorted(((dist, target) for (dist, target) in zip(distances, self.y)), key=lambda x: x[0])\n",
    "\n",
    "        # Get targets of the k-nn and aggregate them (most common one or\n",
    "        # average).\n",
    "        neighbors_targets = [target for (_, target) in neighbors[: self.k]]\n",
    "\n",
    "        return self.aggregate(neighbors_targets)\n",
    "\n",
    "\n",
    "class KNNClassifier(KNNBase):\n",
    "    \"\"\"Nearest neighbors classifier.\n",
    "\n",
    "    Note: if there is a tie for the most common label among the neighbors, then\n",
    "    the predicted label is arbitrary.\"\"\"\n",
    "\n",
    "    def aggregate(self, neighbors_targets):\n",
    "        \"\"\"Return the most common target label.\"\"\"\n",
    "\n",
    "        most_common_label = Counter(neighbors_targets).most_common(1)[0][0]\n",
    "        return most_common_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "This Python script defines and executes a classification task using a k-nearest neighbors (KNN) algorithm from a synthetic dataset.\n",
    "\n",
    "[[bo back to the topic]](#base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification accuracy 0.96\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "except ImportError:\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "def classification():\n",
    "    X, y = make_classification(\n",
    "        n_samples=500,\n",
    "        n_features=5,\n",
    "        n_informative=5,\n",
    "        n_redundant=0,\n",
    "        n_repeated=0,\n",
    "        n_classes=2,\n",
    "        random_state=1111,\n",
    "        class_sep=1.5,\n",
    "    )\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1111)\n",
    "\n",
    "    clf = KNNClassifier(k=7, distance_func=euclidean_distance)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    print(\"classification accuracy\", accuracy(y_test, predictions))\n",
    "    #print(classification_report(y_test, predictions))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    classification()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved Algorithm\n",
    "[[go back to the top]](#table-of-contents)\n",
    "\n",
    "In this chapter we will approach bagging [[more about bagging]](#bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_Bagging:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "    def predict(self, X,i):\n",
    "        predictions = list()\n",
    "        for x in X:\n",
    "            if i==0:\n",
    "                # calculate distances to all training examples\n",
    "                distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "\n",
    "                # get k-nearest neighbors\n",
    "                k_indices = np.argsort(distances)[:self.k]\n",
    "                k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "                unique_classes,counts=np.unique(k_nearest_labels, return_counts=True)\n",
    "                most_frequent_label=unique_classes[np.argmax(counts)]\n",
    "                predictions.append(most_frequent_label)\n",
    "                \n",
    "            elif i==1:\n",
    "                # calculate distances to all training examples\n",
    "                distances = [cosine_similarity(x, x_train) for x_train in self.X_train]\n",
    "\n",
    "                # get k-nearest neighbors\n",
    "                k_indices = np.argsort(distances)[:self.k]\n",
    "                k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "                unique_classes,counts=np.unique(k_nearest_labels, return_counts=True)\n",
    "                most_frequent_label=unique_classes[np.argmax(counts)]\n",
    "                predictions.append(most_frequent_label)\n",
    "                \n",
    "            elif i==2:\n",
    "                # calculate distances to all training examples\n",
    "                distances = [manhattan_distance(x, x_train) for x_train in self.X_train]\n",
    "\n",
    "                # get k-nearest neighbors\n",
    "                k_indices = np.argsort(distances)[:self.k]\n",
    "                k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "                unique_classes,counts=np.unique(k_nearest_labels, return_counts=True)\n",
    "                most_frequent_label=unique_classes[np.argmax(counts)]\n",
    "                predictions.append(most_frequent_label)\n",
    "                \n",
    "            elif i==3:\n",
    "                # calculate distances to all training examples\n",
    "                distances = [jaccard_distance(x, x_train) for x_train in self.X_train]\n",
    "\n",
    "                # get k-nearest neighbors\n",
    "                k_indices = np.argsort(distances)[:self.k]\n",
    "                k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "                unique_classes,counts=np.unique(k_nearest_labels, return_counts=True)\n",
    "                most_frequent_label=unique_classes[np.argmax(counts)]\n",
    "                predictions.append(most_frequent_label)\n",
    "                \n",
    "            elif i==4:\n",
    "                distances = list()\n",
    "                for x_train in self.X_train:\n",
    "                    xMm = x_train - np.mean(self.X_train, axis=0)\n",
    "                    cov = np.cov(np.transpose(self.X_train))\n",
    "                    invcoveM = np.linalg.inv(cov)\n",
    "                    np.set_printoptions(suppress=True)\n",
    "                    tem1 = np.dot(xMm,invcoveM)\n",
    "                    tem2 = np.dot(tem1, np.transpose(xMm))\n",
    "                    MD = np.sqrt(tem2)\n",
    "                    resultado = np.reshape(MD,-1)\n",
    "                    resultado_final = float(np.reshape(MD,-1))\n",
    "                    distances.append(resultado_final)\n",
    "                # get k-nearest neighbors\n",
    "                k_indices = np.argsort(distances)[:self.k]\n",
    "                k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "                unique_classes,counts=np.unique(k_nearest_labels, return_counts=True)\n",
    "                most_frequent_label=unique_classes[np.argmax(counts)]\n",
    "                most_common_str = str(most_frequent_label)\n",
    "                predictions.append(most_common_str)\n",
    "                \n",
    "        return predictions\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        y_proba = []\n",
    "        for sample in X:\n",
    "            distances = np.sqrt(np.sum(((self.X_train - sample)) ** 2, axis=1))\n",
    "            sorted_indices = np.argsort(distances)\n",
    "            k_indices = sorted_indices[:self.k]\n",
    "            k_nearest_classes = self.y_train[k_indices]\n",
    "            unique_classes, counts = np.unique(k_nearest_classes, return_counts=True)\n",
    "            class_frequencies = counts / self.k  # relative frequency of the classes\n",
    "            y_proba.append(class_frequencies)\n",
    "        return np.array(y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN-Features\n",
    "[[go back to the topic]](#improved-algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_Features:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "    def predict(self, X):\n",
    "        predictions = [self._predict(x) for x in X]\n",
    "        return predictions\n",
    "    \n",
    "    def _predict(self, x):\n",
    "        predictions = list()\n",
    "        distances = [euclidean_distance_features(x, x_train) for x_train in self.X_train]\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        k_nearest_labels = [self.y_train.reset_index(drop=True)[i] for i in k_indices]\n",
    "        k_nearest_labels = list(self.y_train.reset_index(drop=True).iloc[k_indices.ravel()])\n",
    "        unique_classes,counts=np.unique(k_nearest_labels, return_counts=True)\n",
    "        most_frequent_label=unique_classes[np.argmax(counts)]\n",
    "        most_common_str = str(most_frequent_label)\n",
    "        predictions.append(most_common_str)\n",
    "        return predictions\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        y_proba = []\n",
    "        for sample in X:\n",
    "            distances = np.sqrt(np.sum(((self.X_train - sample)) ** 2, axis=1))\n",
    "            sorted_indices = np.argsort(distances)\n",
    "            k_indices = sorted_indices[:self.k]\n",
    "            k_nearest_classes = self.y_train[k_indices]\n",
    "            unique_classes, counts = np.unique(k_nearest_classes, return_counts=True)\n",
    "            class_frequencies = counts / self.k  # relative frequency of the classes\n",
    "            y_proba.append(class_frequencies)\n",
    "        return np.array(y_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Statistics\n",
    "[[go back to the topic]](#improved-algorithm)\n",
    "\n",
    "This section provides a suite of Python functions tailored for visual assessment and statistical evaluation of machine learning models, with a particular emphasis on different configurations of the k-Nearest Neighbors (k-NN) algorithm. Each function in this section is crafted to perform specific analyses and visualizations that contribute to a comprehensive understanding of model behavior and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ds2D(X,y):\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_features = pca.fit_transform(X)\n",
    "    \n",
    "    pca_df = pd.DataFrame(\n",
    "        data=pca_features, \n",
    "        columns=['PC1', 'PC2'])\n",
    "    pca_df['target'] = y\n",
    "    pca_df['target'] = pca_df['target']\n",
    "    \n",
    "    sns.scatterplot(x=pca_df['PC1'],y=pca_df['PC2'],hue=pca_df['target'],palette=\"deep\")\n",
    "    plt.title('2D PCA Graph')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(model_fit,X_test,y_test,y_train,predictions):\n",
    "    # Obtain unique classes\n",
    "    y_pred = predictions\n",
    "    unique_classes = np.unique(y_train)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                  display_labels=unique_classes)\n",
    "    disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN(K-Nearest Neighbors)\n",
    "[[go back to the topic]](#chosen-algorithm)\n",
    "\n",
    "yada yada yada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "[[go back to the topic]](#improved-algorithm)\n",
    "\n",
    "Bagging, short for Bootstrap Aggregating, is an ensemble machine learning technique designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
